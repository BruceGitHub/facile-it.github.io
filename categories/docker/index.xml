<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Docker on Facile.it Engineering</title>
    <link>engineering.facile.it/categories/docker/</link>
    <description>Recent content in Docker on Facile.it Engineering</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 19 Oct 2015 00:00:00 +0000</lastBuildDate>
    <atom:link href="engineering.facile.it/categories/docker/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Da sviluppo a produzione con Docker e AWS Elastic Beanstalk</title>
      <link>/engineering.facile.it/blog/ita/da-sviluppo-a-produzione-con-docker-e-aws-elastic-beanstalk/</link>
      <pubDate>Mon, 19 Oct 2015 00:00:00 +0000</pubDate>
      
      <guid>/engineering.facile.it/blog/ita/da-sviluppo-a-produzione-con-docker-e-aws-elastic-beanstalk/</guid>
      <description>

&lt;h2 id=&#34;in-locale-funzionava:242a8db2bfd7fdd1c283c509db3a4bdb&#34;&gt;In locale funzionava&lt;/h2&gt;

&lt;p&gt;Questo articolo si rivolge a chi ha già una &lt;a href=&#34;https://docs.docker.com/articles/basics&#34;&gt;conoscenza base di docker&lt;/a&gt; e del suo funzionamento e sta cercando come avanzare al passo successivo, usandolo quotidianamente in sviluppo e in produzione.&lt;/p&gt;

&lt;p&gt;Avere un ambiente di sviluppo/test &lt;strong&gt;il più simile possibile&lt;/strong&gt; a quello di produzione aiuta molto nel garantire un &lt;strong&gt;corretto funzionamento dopo il deploy&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;In uno scenario tipico, lo sviluppatore ha installati sulla propria macchina locale tutti i servizi da cui dipende la sua applicazione, il che comporta quanto segue:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;nessun tipo di isolamento tra progetti che usano gli stessi servizi (versione, configurazione, dati);&lt;/li&gt;
&lt;li&gt;è difficile avere e mantenere in locale la stessa versione e la stessa configurazione dei servizi in produzione;&lt;/li&gt;
&lt;li&gt;condividere l&amp;rsquo;ambiente di sviluppo con colleghi e collaboratori è difficile se non impossibile;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Tutto questo conduce ad una delle peggiori frasi che io abbia mai sentito in tutta la mia esperienza lavorativa:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;It works on my machine &lt;em&gt;(in locale funzionava)&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&#34;engineering.facile.it/images/from-development-to-production-with-docker-and-amazon-ecs/wmm.jpg&#34; alt=&#34;It works on my machine meme&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Potreste pensare che avrei potuto ottenere gli stessi risultati usando Vagrant o una classica macchina virtuale, ma questa soluzione non mi avrebbe dato i benefici di avere un layer di astrazione aggiuntivo senza dovermi preoccupare dell&amp;rsquo;overhead. Infatti posso avere molti più container che girano su una singola macchina di quelli che avrei avuto con la semplice virtualizzazione.&lt;/p&gt;

&lt;h2 id=&#34;bookshelf-uno-scaffale-virtuale:242a8db2bfd7fdd1c283c509db3a4bdb&#34;&gt;Bookshelf: uno scaffale virtuale&lt;/h2&gt;

&lt;p&gt;Per snellire questo articolo ho preparato un&amp;rsquo;&lt;a href=&#34;https://github.com/pennyphp/bookshelf&#34;&gt;applicazione demo&lt;/a&gt; basata su &lt;a href=&#34;http://github.com/pennyphp/penny&#34;&gt;Penny PHP Framework&lt;/a&gt;: è una semplice applicazione per l&amp;rsquo;archiviazione di libri, che consente all&amp;rsquo;utente di creare e visualizzare una lista di libri.&lt;/p&gt;

&lt;h4 id=&#34;download-e-dipendenze:242a8db2bfd7fdd1c283c509db3a4bdb&#34;&gt;Download e dipendenze&lt;/h4&gt;

&lt;p&gt;Per prima cosa, scarichiamo l&amp;rsquo;applicazione dal suo repository:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;git clone https://github.com/pennyphp/bookshelf
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Le dipendenze in PHP sono gestite attraverso &lt;a href=&#34;https://getcomposer.org/&#34;&gt;composer&lt;/a&gt;, e per soddisfarle basta digitare il comando:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;composer install
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Gli assets del frontend sono gestiti attraverso &lt;a href=&#34;http://bower.io&#34;&gt;Bower&lt;/a&gt; + &lt;a href=&#34;http://gruntjs.com/&#34;&gt;Grunt&lt;/a&gt;; i due seguenti comandi scaricheranno e compileranno le dipendenze e produrranno gli assets direttamente nella cartella pubblica:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;npm install
grunt dev
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;avviare-l-ambiente-di-sviluppo:242a8db2bfd7fdd1c283c509db3a4bdb&#34;&gt;Avviare l&amp;rsquo;ambiente di sviluppo&lt;/h4&gt;

&lt;p&gt;Come potete vedere l&amp;rsquo;applicazione demo è distribuita con un ambiente di sviluppo docker che potete trovare nella cartella &lt;a href=&#34;https://github.com/pennyphp/bookshelf/tree/master/docker/development&#34;&gt;docker/development&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Osservando il contenuto di &lt;code&gt;docker/development&lt;/code&gt; possiamo trovare altre due cartelle:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;nginx/&lt;/code&gt;: questa directory contiene un Dockerfile che eredita l&amp;rsquo;immagine da &lt;a href=&#34;https://github.com/fntlnz/dockerfiles/tree/master/nginx&#34;&gt;fntlnz/nginx&lt;/a&gt; per crearne una nuova con la configurazione nginx necessaria;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;fpm/&lt;/code&gt;: questa directory contiene un Dockerfile che eredita l&amp;rsquo;immagine da &lt;a href=&#34;https://github.com/fntlnz/dockerfiles/tree/master/php&#34;&gt;fntlnz/php&lt;/a&gt; per crearne una nuova con la configurazione e le estensioni di php-fpm necessarie;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Dal momento che non abbiamo Elastic Beanstalk sulla nostra macchina locale (ne parleremo in seguito) e abbiamo bisogno di un modo per orchestrare i nostri container, lo faremo utilizzando &lt;strong&gt;docker-compose&lt;/strong&gt;. Ho deciso di usare Docker Compose al posto del comando &lt;a href=&#34;http://docs.aws.amazon.com/elasticbeanstalk/latest/dg/eb3-local.html&#34;&gt;&lt;strong&gt;eb local&lt;/strong&gt;&lt;/a&gt; (che consente di far girare l&amp;rsquo;ambiente di elastic beanstalk in locale) perché allo stato dell&amp;rsquo;arte compose è più facile da usare e mantenere in locale.&lt;/p&gt;

&lt;h6 id=&#34;il-file-docker-compose-yml:242a8db2bfd7fdd1c283c509db3a4bdb&#34;&gt;Il file &lt;code&gt;docker-compose.yml&lt;/code&gt;&lt;/h6&gt;

&lt;p&gt;Per farlo dobbiamo creare un file &lt;code&gt;docker-compose.yml&lt;/code&gt; nella nostra root di progetto.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;cp docker/docker-compose.yml.development docker-compose.yml
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;A questo punto, nel nostro &lt;code&gt;docker-compose.yml&lt;/code&gt; dovremmo avere quattro container da avviare:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;il container &lt;strong&gt;Nginx&lt;/strong&gt;, che contiene un paragrafo server in ascolto sulla porta 80.&lt;/li&gt;
&lt;li&gt;il container &lt;strong&gt;fpm&lt;/strong&gt;, che condivide un volume con la macchina host in modo da poter modificare il codice senza bisogno di ricostruire il container; inoltre, il container è collegato al container mysql per consentire agli script php di connettervisi;&lt;/li&gt;
&lt;li&gt;il container &lt;strong&gt;mysql&lt;/strong&gt;, che conterrà i nostri dati di sviluppo;&lt;/li&gt;
&lt;li&gt;il container &lt;strong&gt;redis&lt;/strong&gt;, usato come cache, principalmente da Doctrine;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Si noti come, dal momento che &lt;a href=&#34;https://docs.docker.com/userguide/dockerlinks/&#34;&gt;i container sono collegati&lt;/a&gt; è possibile accedere ad un servizio esposto usando il nome assegnato al container collegato; ad esempio, nel nostro caso il container fpm è &lt;a href=&#34;https://github.com/pennyphp/bookshelf/blob/2e55738da9ff9e45fa44add9d97280635e95399d/docker/docker-compose.yml.development#L19-L20&#34;&gt;collegato al container mysql&lt;/a&gt;: è per questo che l&amp;rsquo;host configurato nella &lt;a href=&#34;https://github.com/pennyphp/bookshelf/blob/2e55738da9ff9e45fa44add9d97280635e95399d/config/doctrine.local.php.dist#L13&#34;&gt;configurazione di doctrine locale&lt;/a&gt; è &lt;code&gt;mysql&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Se non l&amp;rsquo;avete ancora fatto, dovrete buildare l&amp;rsquo;immagine &lt;code&gt;fpm&lt;/code&gt; e scaricare le immagini &lt;code&gt;nginx&lt;/code&gt;, &lt;code&gt;mysql&lt;/code&gt; e &lt;code&gt;redis&lt;/code&gt;; per farlo, digitate il comando:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker-compose build
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Ora che avete tutto ciò che vi serve potete avviare i container con:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker-compose up
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;A questo punto i quattro container dovrebbero essere in esecuzione: potete verificare che tutto sia a posto con il comando &lt;code&gt;docker ps&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Per proseguire, abbiamo bisogno di conoscere l&amp;rsquo;indirizzo ip del container nginx. Il port forwarding del container nginx è configurato come &lt;code&gt;80:80&lt;/code&gt;, perciò è disponibile su &lt;strong&gt;linux&lt;/strong&gt; agli indirizzi &lt;code&gt;127.0.0.1:80&lt;/code&gt; e &lt;code&gt;localhost:80&lt;/code&gt;, mentre su &lt;strong&gt;OS X&lt;/strong&gt; all&amp;rsquo;indirizzo associato alla docker-machine; per identificarlo, usare il comando:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker-machine env &amp;lt;yourmachinename&amp;gt; | grep DOCKER_HOST
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;È ora di collegarci all&amp;rsquo;ip del nostro container nginx!&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;engineering.facile.it/images/from-development-to-production-with-docker-and-amazon-ecs/books.png&#34; alt=&#34;Bookshelf screenshot&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Yay! Il nostro ambiente di sviluppo è in esecuzione!&lt;/p&gt;

&lt;h4 id=&#34;configurare-e-attivare-l-ambiente-di-produzione:242a8db2bfd7fdd1c283c509db3a4bdb&#34;&gt;Configurare e attivare l&amp;rsquo;ambiente di produzione&lt;/h4&gt;

&lt;p&gt;A questo punto ci serve un modo per rilasciare la nostra applicazione in produzione che possa: eseguire container Docker, scalare senza intoppi e possibilmente aver già installato altri interessanti componenti come, ad esempio, per il monitoring.&lt;/p&gt;

&lt;p&gt;La scelta è caduta su &lt;a href=&#34;https://aws.amazon.com/elasticbeanstalk&#34;&gt;AWS Elastic Beanstalk&lt;/a&gt; ha tutto ciò che abbiamo elencato ed ha inoltre una tariffazione più competitiva con un &lt;a href=&#34;https://aws.amazon.com/free/&#34;&gt;Free Tier&lt;/a&gt; iniziale, sufficiente per far girare questa demo.&lt;/p&gt;

&lt;p&gt;Prima di iniziare abbiamo bisogno di un account &lt;strong&gt;Amazon Web Services&lt;/strong&gt;; se non ne avete ancora uno, potete crearlo &lt;a href=&#34;https://aws.amazon.com/account&#34;&gt;qui&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Per configurare, rilasciare e gestire la nostra infrastruttura avremo bisogno del &lt;a href=&#34;http://docs.aws.amazon.com/elasticbeanstalk/latest/dg/eb-cli3-install.html&#34;&gt;comando eb&lt;/a&gt;; per installarlo, digitare:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;pip install awsebcli
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Per avere accesso alla piattaforma dalla vostra riga di comando usando il comando &lt;strong&gt;eb&lt;/strong&gt; dovrete configurare uno &lt;a href=&#34;http://docs.aws.amazon.com/elasticbeanstalk/latest/dg/AWSHowTo.iam.roles.aeb.html&#34;&gt;&lt;strong&gt;IAM ROLE&lt;/strong&gt;&lt;/a&gt; ed associarlo ad uno &lt;a href=&#34;http://docs.aws.amazon.com/IAM/latest/UserGuide/id_users_create.html&#34;&gt;&lt;strong&gt;IAM User&lt;/strong&gt;&lt;/a&gt;. La creazione assistita di uno IAM User vi &lt;strong&gt;darà due chiavi&lt;/strong&gt;, chiamate &lt;em&gt;AWS Access Key ID&lt;/em&gt; e &lt;em&gt;AWS Secret Access Key&lt;/em&gt;. Ci serviranno durante il prossimo passaggio.&lt;/p&gt;

&lt;p&gt;A questo punto possiamo &lt;strong&gt;initialize&lt;/strong&gt; il nostro progetto Bookshelf. Questo comando ci chiederà le due Access keys, oltre che alcune domande durante l&amp;rsquo;installazione.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;eb init
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Ora che il progetto è inizializzato dobbiamo &lt;strong&gt;creare un nuovo ambiente&lt;/strong&gt;. Questo comando creerà effettivamente un&amp;rsquo;istanza &lt;strong&gt;t2.micro EC2&lt;/strong&gt;, i gruppi di sicurezza, il load balancer, le notifiche cloudwatch ecc..&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;eb create bookshelf-production
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Prima di rilasciare l&amp;rsquo;applicazione in produzione dobbiamo generare un &lt;a href=&#34;https://github.com/settings/tokens/new&#34;&gt;Token Github per composer&lt;/a&gt;.
Questo è necessario per scaricare tutte le dipendenze senza intoppi.
Per aggiungere il token all&amp;rsquo;ambiente:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;eb setenv COMPOSER_TOKEN=&amp;lt;your-token-here&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Ora potete verificare che il sistema sia pronto digitando:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;eb status
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Quando lo stato dell&amp;rsquo;applicazione diventa &lt;strong&gt;Ready&lt;/strong&gt; potete a tutti gli effetti pubblicare l&amp;rsquo;applicazione con:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;eb deploy
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Il deployment creerà i container descritti in &lt;a href=&#34;https://github.com/pennyphp/bookshelf/blob/2e55738da9ff9e45fa44add9d97280635e95399d/Dockerrun.aws.json&#34;&gt;Dockerrun.aws.json&lt;/a&gt; e i files descritti in &lt;a href=&#34;https://github.com/pennyphp/bookshelf/blob/2e55738da9ff9e45fa44add9d97280635e95399d/.ebextensions/dependencies.config&#34;&gt;dependencies.config&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Se vi state chiedendo cosa sia realmente il file &lt;strong&gt;Dockerrun.aws.json&lt;/strong&gt;, basta dire che sta ad Elastic Beanstalk come &lt;code&gt;docker-compose.yml&lt;/code&gt; sta all&amp;rsquo;ambiente locale.&lt;/p&gt;

&lt;p&gt;I file contenuti in &lt;a href=&#34;https://github.com/pennyphp/bookshelf/blob/2e55738da9ff9e45fa44add9d97280635e95399d/.ebextensions/&#34;&gt;.ebextensions&lt;/a&gt; consentono di personalizzare e configurare il software da cui la vostra applicazione dipende. Il file &lt;strong&gt;dependencies.config&lt;/strong&gt; è uno di questi. È proprio lui a risolvere le dipendenze di composer, a compilare gli asset del frontend con grunt e bower e a creare l&amp;rsquo;immagine PHP FPM usata nel &lt;a href=&#34;https://github.com/pennyphp/bookshelf/blob/2e55738da9ff9e45fa44add9d97280635e95399d/docker/production/fpm/Dockerfile&#34;&gt;Dockerfile&lt;/a&gt; di produzione. È importante notare che l&amp;rsquo;immagine viene nuovamente costruita solo se il Dockerfile viene modificato.&lt;/p&gt;

&lt;p&gt;Come avrete notato, [Dockerrun.aws.json](&lt;a href=&#34;https://github.com&#34;&gt;https://github.com&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;La configurazione di default dell&amp;rsquo;applicazione Bookshelf riceve i parametri di connessione a Mysql e Redis &lt;a href=&#34;https://github.com/pennyphp/bookshelf/blob/2e55738da9ff9e45fa44add9d97280635e95399d/config/doctrine.global.php&#34;&gt;dalle variabili d&amp;rsquo;ambiente&lt;/a&gt; che sono:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;MYSQL_HOST
MYSQL_PORT
MYSQL_USERNAME
MYSQL_PASSWORD
MYSQL_DATABASE
REDIS_HOST
REDIS_PORT
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Ognuna di queste variabili d&amp;rsquo;ambiente può essere impostata usando il comando che abbiamo precedentemente usato per &lt;code&gt;COMPOSER_TOKEN&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Potete ottenere i parametri di connessione per Mysql e Redis dopo aver creato &lt;a href=&#34;http://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_CreateInstance.html&#34;&gt;un&amp;rsquo;istanza RDS Mysql DB&lt;/a&gt; e un &lt;a href=&#34;http://docs.aws.amazon.com/opsworks/latest/userguide/other-services-redis-cluster.html&#34;&gt;Cluster ElastiCache Redis&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;A questo punto, con i container nginx e fpm in esecuzione e i database configurati, potete digitare &lt;code&gt;eb open&lt;/code&gt; per aprire l&amp;rsquo;applicazione in produzione e verificare se tutto è ok!&lt;/p&gt;

&lt;p&gt;La vostra infrastruttura, così com&amp;rsquo;è, è anche già pronta per scalare automaticamente; per muovere i primi passi in questa direzione potete dare un&amp;rsquo;occhiata al comando &lt;a href=&#34;http://docs.aws.amazon.com/elasticbeanstalk/latest/dg/eb3-scale.html&#34;&gt;&lt;code&gt;eb scale&lt;/code&gt;&lt;/a&gt; e alla &lt;a href=&#34;http://docs.aws.amazon.com/elasticbeanstalk/latest/dg/using-features.managing.as.html&#34;&gt;documentazione di AWS&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Troubleshooting&lt;/strong&gt;: Se qualcosa dovesse andare storto potete accedere via ssh nella macchina Elastic Beanstalk EC2 con &lt;code&gt;eb ssh&lt;/code&gt; e analizzare lo stato dei container usando strumenti che già conoscete come &lt;code&gt;docker logs&lt;/code&gt;.&lt;/p&gt;

&lt;h4 id=&#34;è-fatta:242a8db2bfd7fdd1c283c509db3a4bdb&#34;&gt;È fatta!&lt;/h4&gt;

&lt;p&gt;Ora potete risparmiare un sacco di tempo automatizzando il vostro workflow con docker ed ottenere un ambiente di sviluppo funzionante, auto-contenuto e condivisibile, pur mantenendolo molto simile alla vostra stabile ed efficiente infrastruttura in esecuzione nell&amp;rsquo;ambiente di produzione, sulle cui risorse avete pieno controllo.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;engineering.facile.it/images/from-development-to-production-with-docker-and-amazon-ecs/good-job.jpg&#34; alt=&#34;congratulations&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>From development to production with Docker and AWS Elastic Beanstalk</title>
      <link>/engineering.facile.it/blog/eng/from-development-to-production-with-docker-and-amazon-ecs/</link>
      <pubDate>Mon, 19 Oct 2015 00:00:00 +0000</pubDate>
      
      <guid>/engineering.facile.it/blog/eng/from-development-to-production-with-docker-and-amazon-ecs/</guid>
      <description>

&lt;h1 id=&#34;it-works-on-my-machine:824629f989995bd0ef3a2fb42ac10127&#34;&gt;It works on my machine&lt;/h1&gt;

&lt;p&gt;This post is addressed to people who already have &lt;a href=&#34;https://docs.docker.com/articles/basics&#34;&gt;basic knowledge about docker&lt;/a&gt;, about how it works and are looking for a way to move to the next step with the goal of using it in development and production day by day.&lt;/p&gt;

&lt;p&gt;Having a development/testing environment &lt;strong&gt;as close as possible&lt;/strong&gt; to the production one helps a lot in assuring that &lt;strong&gt;things will behave correctly when delivered&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;In a typical scenario, the developer has all the services on which the application depends installed on his local machine, which means the following:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;there&amp;rsquo;s no isolation between projects using the same services (versions, configurations, data);&lt;/li&gt;
&lt;li&gt;it&amp;rsquo;s hard to have and maintain production-like services&amp;rsquo; versions and configurations in development;&lt;/li&gt;
&lt;li&gt;sharing the development environment with co-workers is difficult if not impossible;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;All of that leads to one of the worst sentences I&amp;rsquo;ve ever heard saying in my experience:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;It works on my machine.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&#34;engineering.facile.it/images/from-development-to-production-with-docker-and-amazon-ecs/wmm.jpg&#34; alt=&#34;It works on my machine meme&#34; /&gt;&lt;/p&gt;

&lt;p&gt;You might think that I could obtain the same results using Vagrant or plain virtual machines but that solution wouldn&amp;rsquo;t give me the benefit of having an extra layer of abstraction without having to worry about the overhead. In fact I can have more and more containers running on a single machine than I can have with virtualization.&lt;/p&gt;

&lt;h1 id=&#34;bookshelf-application:824629f989995bd0ef3a2fb42ac10127&#34;&gt;Bookshelf application&lt;/h1&gt;

&lt;p&gt;To streamline this article I prepared a &lt;a href=&#34;https://github.com/pennyphp/bookshelf&#34;&gt;demo application&lt;/a&gt; using the &lt;a href=&#34;http://github.com/pennyphp/penny&#34;&gt;Penny PHP Framework&lt;/a&gt;: it&amp;rsquo;s a simple book archiving application, that allows the user to create and view a list of books.&lt;/p&gt;

&lt;h2 id=&#34;download-and-dependencies:824629f989995bd0ef3a2fb42ac10127&#34;&gt;Download and dependencies&lt;/h2&gt;

&lt;p&gt;First, download the demo application from its repository:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;git clone https://github.com/pennyphp/bookshelf
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;PHP Dependencies are managed through &lt;a href=&#34;https://getcomposer.org/&#34;&gt;composer&lt;/a&gt;, and to get them just issue the following:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;composer install
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Frontend assets are managed through &lt;a href=&#34;http://bower.io&#34;&gt;Bower&lt;/a&gt; + &lt;a href=&#34;http://gruntjs.com/&#34;&gt;Grunt&lt;/a&gt;; the following two commands will respectively download build dependencies and then build the assets, by copying them in the public directory:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;npm install
grunt dev
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;up-and-running-development-environment:824629f989995bd0ef3a2fb42ac10127&#34;&gt;Up and running development environment&lt;/h2&gt;

&lt;p&gt;As you can see the demo app comes with a docker development environment that can be found under the &lt;a href=&#34;https://github.com/pennyphp/bookshelf/tree/master/docker/development&#34;&gt;docker/development&lt;/a&gt; folder.&lt;/p&gt;

&lt;p&gt;By inspecting the content of the &lt;code&gt;docker/development&lt;/code&gt; folder we can find two directories:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;nginx/&lt;/code&gt;: this directory contains a Dockerfile that inherits from the &lt;a href=&#34;https://github.com/fntlnz/dockerfiles/tree/master/nginx&#34;&gt;fntlnz/nginx&lt;/a&gt; image to create a new one with the needed nginx configurations;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;fpm/&lt;/code&gt;: this directory contains a Dockerfile that inherits from the &lt;a href=&#34;https://github.com/fntlnz/dockerfiles/tree/master/php&#34;&gt;fntlnz/php&lt;/a&gt; image to create a new one with the needed php-fpm configurations and extensions;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Because we don&amp;rsquo;t have Elastic Beanstalk on our local machine (we&amp;rsquo;ll talk about it later) and we need a way to orchestrate our containers, we&amp;rsquo;ll do it by using &lt;strong&gt;docker-compose&lt;/strong&gt;. I decided to use Docker Compose instead of using the &lt;a href=&#34;http://docs.aws.amazon.com/elasticbeanstalk/latest/dg/eb3-local.html&#34;&gt;&lt;strong&gt;eb local&lt;/strong&gt;&lt;/a&gt; command (which allows to run elastic beanstalk environment in local) because at the state of art compose is easier to use and to manage in local.&lt;/p&gt;

&lt;h4 id=&#34;the-docker-compose-yml:824629f989995bd0ef3a2fb42ac10127&#34;&gt;The &lt;code&gt;docker-compose.yml&lt;/code&gt;&lt;/h4&gt;

&lt;p&gt;In order to do so we have to create a &lt;code&gt;docker-compose.yml&lt;/code&gt; in our project root.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;cp docker/docker-compose.yml.development docker-compose.yml
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;At this point, in our &lt;code&gt;docker-compose.yml&lt;/code&gt; we should have four containers to start:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;the &lt;strong&gt;Nginx&lt;/strong&gt; container, which contains a server block  for the bookshelf application listening on port 80.&lt;/li&gt;
&lt;li&gt;the &lt;strong&gt;fpm&lt;/strong&gt; container, which does have a shared volume with the host machine so you can change the code without the need to rebuild the container image; also, the container is linked with the mysql container to allow mysql access from php scripts;&lt;/li&gt;
&lt;li&gt;the &lt;strong&gt;mysql&lt;/strong&gt; container, which will contain our development data;&lt;/li&gt;
&lt;li&gt;the &lt;strong&gt;redis&lt;/strong&gt; container, used for caching purposes, mainly by Doctrine;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Please note that since &lt;a href=&#34;https://docs.docker.com/userguide/dockerlinks/&#34;&gt;containers are linked&lt;/a&gt; you can access to an exposed service by using the name given to the linked container; for example, in our case the fpm container is &lt;a href=&#34;https://github.com/pennyphp/bookshelf/blob/2e55738da9ff9e45fa44add9d97280635e95399d/docker/docker-compose.yml.development#L19-L20&#34;&gt;linked to the mysql container&lt;/a&gt;: that&amp;rsquo;s why the configured host is &lt;code&gt;mysql&lt;/code&gt; in the &lt;a href=&#34;https://github.com/pennyphp/bookshelf/blob/2e55738da9ff9e45fa44add9d97280635e95399d/config/doctrine.local.php.dist#L13&#34;&gt;doctrine local connection configuration&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;If you haven&amp;rsquo;t done it yet, you need to build the &lt;code&gt;fpm&lt;/code&gt; docker image and download the &lt;code&gt;nginx&lt;/code&gt;, &lt;code&gt;mysql&lt;/code&gt; and &lt;code&gt;redis&lt;/code&gt; images; to do so, issue the following:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker-compose build
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now that you have all what you need you can start the containers with:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker-compose up
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;At this point the four containers should be up and running: you can check if everything&amp;rsquo;s okay by issuing the &lt;code&gt;docker ps&lt;/code&gt; command.&lt;/p&gt;

&lt;p&gt;To proceed, we need to know the ip address of our nginx container. Since the nginx container&amp;rsquo;s port forwarding configuration is &lt;code&gt;80:80&lt;/code&gt;, on &lt;strong&gt;linux&lt;/strong&gt; it should be available at &lt;code&gt;127.0.0.1:80&lt;/code&gt; or &lt;code&gt;localhost:80&lt;/code&gt;, while on &lt;strong&gt;OS X&lt;/strong&gt; it should be available at the ip address associated to the docker-machine host; to retrieve it, issue the following:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker-machine env &amp;lt;yourmachinename&amp;gt; | grep DOCKER_HOST
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It&amp;rsquo;s time to point your browser to the nginx container ip address!&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;engineering.facile.it/images/from-development-to-production-with-docker-and-amazon-ecs/books.png&#34; alt=&#34;Bookshelf screenshot&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Yay! Our development environment is up and running!&lt;/p&gt;

&lt;h2 id=&#34;up-and-running-production-environment:824629f989995bd0ef3a2fb42ac10127&#34;&gt;Up and running production environment&lt;/h2&gt;

&lt;p&gt;At this point we need a solution to deploy our application in production that can: run Docker containers, scale without hassle and possibly have other nice things already setup like, let&amp;rsquo;s say, monitoring.&lt;/p&gt;

&lt;p&gt;The choice fell on &lt;a href=&#34;https://aws.amazon.com/elasticbeanstalk&#34;&gt;AWS Elastic Beanstalk&lt;/a&gt; because it has all those things and in addition it has a more competitive pricing model with an initial &lt;a href=&#34;https://aws.amazon.com/free/&#34;&gt;Free Tier&lt;/a&gt; which it is enough to run this demo.&lt;/p&gt;

&lt;p&gt;Before we start we need an &lt;strong&gt;Amazon Web Services&lt;/strong&gt; account, if you don&amp;rsquo;t have one yet, you can create it &lt;a href=&#34;https://aws.amazon.com/account&#34;&gt;here&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To configure, deploy and manage our infrastructure we are going to need the &lt;a href=&#34;http://docs.aws.amazon.com/elasticbeanstalk/latest/dg/eb-cli3-install.html&#34;&gt;eb command&lt;/a&gt;, to get it:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;pip install awsebcli
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In order to obtain access to the platform from your command line using the &lt;strong&gt;eb&lt;/strong&gt; command you have to setup an &lt;a href=&#34;http://docs.aws.amazon.com/elasticbeanstalk/latest/dg/AWSHowTo.iam.roles.aeb.html&#34;&gt;&lt;strong&gt;IAM ROLE&lt;/strong&gt;&lt;/a&gt; and associate it to an &lt;a href=&#34;http://docs.aws.amazon.com/IAM/latest/UserGuide/id_users_create.html&#34;&gt;&lt;strong&gt;IAM User&lt;/strong&gt;&lt;/a&gt;. The IAM User creation wizard will &lt;strong&gt;give you two keys&lt;/strong&gt;, namely the &lt;em&gt;AWS Access Key ID&lt;/em&gt; and the &lt;em&gt;AWS Secret Access Key&lt;/em&gt;. We are going to need them during the next step.&lt;/p&gt;

&lt;p&gt;At this point we can &lt;strong&gt;initialize&lt;/strong&gt; our bookshelf project. This command will prompt us for the two Access keys plus a few question about our setup.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;eb init
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now that the project is initialized we have to &lt;strong&gt;create a new environment&lt;/strong&gt;. This will actually start a &lt;strong&gt;t2.micro EC2&lt;/strong&gt; instance, create the security groups, the load balancer, cloudwatch alarms etc..&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;eb create bookshelf-production
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Before deploying the application to production we have to generate a &lt;a href=&#34;https://github.com/settings/tokens/new&#34;&gt;Github Token for composer&lt;/a&gt;.
This is needed to allow composer to download dependencies without hassle.
To add the token to your environment:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;eb setenv COMPOSER_TOKEN=&amp;lt;your-token-here&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now you can check if the system is ready issuing a:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;eb status
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;When the status becomes &lt;strong&gt;Ready&lt;/strong&gt; you can actually deploy the application with a:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;eb deploy
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The deployment will create the containers described in the &lt;a href=&#34;https://github.com/pennyphp/bookshelf/blob/2e55738da9ff9e45fa44add9d97280635e95399d/Dockerrun.aws.json&#34;&gt;Dockerrun.aws.json&lt;/a&gt; and create the files described in the &lt;a href=&#34;https://github.com/pennyphp/bookshelf/blob/2e55738da9ff9e45fa44add9d97280635e95399d/.ebextensions/dependencies.config&#34;&gt;dependencies.config&lt;/a&gt; file.&lt;/p&gt;

&lt;p&gt;If you are asking yourslef what the &lt;strong&gt;Dockerrun.aws.json&lt;/strong&gt; actually is, suffice it to say that is to Elastic beanstalk as the &lt;code&gt;docker-compose.yml&lt;/code&gt; is to the local environment.&lt;/p&gt;

&lt;p&gt;The files contained in the &lt;a href=&#34;https://github.com/pennyphp/bookshelf/blob/2e55738da9ff9e45fa44add9d97280635e95399d/.ebextensions/&#34;&gt;.ebextensions&lt;/a&gt; allows you to customize and configure the software that your application depends on. The &lt;strong&gt;dependencies.config&lt;/strong&gt; is one of them. It actually resolves composer dependencies, build frontend assets using grunt and bower and create the PHP FPM image using the production &lt;a href=&#34;https://github.com/pennyphp/bookshelf/blob/2e55738da9ff9e45fa44add9d97280635e95399d/docker/production/fpm/Dockerfile&#34;&gt;Dockerfile&lt;/a&gt;. It&amp;rsquo;s important to note that the image is rebuilt only if changes are made to the Dockerfile.&lt;/p&gt;

&lt;p&gt;As you may have noticed, the &lt;a href=&#34;https://github.com/pennyphp/bookshelf/blob/2e55738da9ff9e45fa44add9d97280635e95399d/Dockerrun.aws.json&#34;&gt;Dockerrun.aws.json&lt;/a&gt; contains definitions just for the Nginx and fpm containers. This is because for &lt;strong&gt;Redis&lt;/strong&gt; and &lt;strong&gt;Mysql&lt;/strong&gt; we are going to use respectively &lt;a href=&#34;https://aws.amazon.com/elasticache/&#34;&gt;&lt;strong&gt;Elasticache&lt;/strong&gt;&lt;/a&gt; and &lt;a href=&#34;https://aws.amazon.com/rds/&#34;&gt;&lt;strong&gt;RDS&lt;/strong&gt;&lt;/a&gt;. RDS and Elasticache are two production ready, scalable and reliable solutions that makes easier to setup a cost-efficient relational database and key value store taking charge of common database administration tasks.&lt;/p&gt;

&lt;p&gt;The Bookshelf application by default is configured to take Mysql and Redis connection parameters &lt;a href=&#34;https://github.com/pennyphp/bookshelf/blob/2e55738da9ff9e45fa44add9d97280635e95399d/config/doctrine.global.php&#34;&gt;from environment variables&lt;/a&gt; which are:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;MYSQL_HOST
MYSQL_PORT
MYSQL_USERNAME
MYSQL_PASSWORD
MYSQL_DATABASE
REDIS_HOST
REDIS_PORT
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Each one of these environment variables can be set using the command we previously used for the &lt;code&gt;COMPOSER_TOKEN&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;You can obtain Mysql and Redis connection parameters after creating an &lt;a href=&#34;http://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_CreateInstance.html&#34;&gt;RDS Mysql DB instance&lt;/a&gt; and an &lt;a href=&#34;http://docs.aws.amazon.com/opsworks/latest/userguide/other-services-redis-cluster.html&#34;&gt;ElastiCache Redis Cluster&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;At this point with the running Nginx and fpm containers and configured databases you can issue an &lt;code&gt;eb open&lt;/code&gt; to open the live production application and see if all&amp;rsquo;s okay!&lt;/p&gt;

&lt;p&gt;As well as ready your infrastructure is also ready to scale and auto scale, to move a first step trough this direction you can take a look at the &lt;a href=&#34;http://docs.aws.amazon.com/elasticbeanstalk/latest/dg/eb3-scale.html&#34;&gt;&lt;code&gt;eb scale&lt;/code&gt;&lt;/a&gt; command and at the &lt;a href=&#34;http://docs.aws.amazon.com/elasticbeanstalk/latest/dg/using-features.managing.as.html&#34;&gt;AWS documentation&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Troubleshooting&lt;/strong&gt;: If something went wrong you can ssh into the elastic beanstalk EC2 machine with a &lt;code&gt;eb ssh&lt;/code&gt; and inspect containers status using tools you already know like &lt;code&gt;docker logs&lt;/code&gt;.&lt;/p&gt;

&lt;h1 id=&#34;you-are-done:824629f989995bd0ef3a2fb42ac10127&#34;&gt;You are done!&lt;/h1&gt;

&lt;p&gt;You can now save a lot of time automating your workflow using docker while having a fully working, self-contained and shareable development environment very close to your running, stable and efficient production infrastructure over which you have full control of the resources.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;engineering.facile.it/images/from-development-to-production-with-docker-and-amazon-ecs/good-job.jpg&#34; alt=&#34;congratulations&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Si fa presto a dire Docker (e OS X)</title>
      <link>/engineering.facile.it/blog/ita/si-fa-presto-a-dire-docker-e-os-x/</link>
      <pubDate>Wed, 22 Jul 2015 00:00:00 +0000</pubDate>
      
      <guid>/engineering.facile.it/blog/ita/si-fa-presto-a-dire-docker-e-os-x/</guid>
      <description>

&lt;p&gt;Di guide per l&amp;rsquo;installazione di Docker su OS X è pieno il web, ma &lt;strong&gt;le soluzioni sono molte&lt;/strong&gt; e spesso scegliere non è facile.
In questo articolo vi mostrerò quello che è stato il mio personale percorso, nella speranza che possa essere utile a chiarirvi le idee e magari evitare qualche buco nell&amp;rsquo;acqua.&lt;/p&gt;

&lt;p&gt;Da sviluppatore web, la mia esigenza è di conservare i sorgenti sulla macchina host e condividerli con la VM; per la natura di PHP, la condivisione deve anche essere molto veloce, poiché ad ogni richiesta i files verranno letti nuovamente dal disco. Nulla di complicato, quindi sono partito dalla cosa più semplice.&lt;/p&gt;

&lt;h2 id=&#34;boot2docker:aeddcc759c6f7b3a77b59769b654e3a1&#34;&gt;boot2docker&lt;/h2&gt;

&lt;p&gt;Probabilmente la soluzione più nota e diffusa, &lt;a href=&#34;https://docs.docker.com/installation/mac/&#34;&gt;boot2docker&lt;/a&gt; è stata la mia prima scelta. Si installa con &lt;code&gt;homebrew&lt;/code&gt; o &lt;code&gt;curl&lt;/code&gt; e viene distribuita con una propria ISO, molto leggera e progettata appositamente per Docker, che gira su VirtualBox.
L&amp;rsquo;unica vera pecca è proprio il protocollo di condivisione nativo di VirtualBox, &lt;code&gt;vboxsf&lt;/code&gt;, che risulta &lt;strong&gt;molto lento&lt;/strong&gt; per progetti di medie dimensioni e rende il caricamento delle pagine lunghissimo.&lt;/p&gt;

&lt;h2 id=&#34;docker-osx:aeddcc759c6f7b3a77b59769b654e3a1&#34;&gt;docker-osx&lt;/h2&gt;

&lt;p&gt;Decido di &lt;a href=&#34;https://github.com/noplay/docker-osx&#34;&gt;provarlo&lt;/a&gt; incuriosito da un collega che ne aveva creato una versione modificata per supportare la &lt;strong&gt;condivisione NFS&lt;/strong&gt;, ma nonostante questo non lo trovo migliore di boot2docker. Inoltre il suo sviluppo è precedente, e il progetto è stato abbandonato quando Docker ha iniziato a supportare ufficialmente boot2docker: è in effetti lo stesso sviluppatore a sconsigliarne l&amp;rsquo;utilizzo da parte di nuovi utenti.&lt;/p&gt;

&lt;h2 id=&#34;vagrant-e-parallels-boot2docker-https-github-com-parallels-boot2docker-vagrant-box:aeddcc759c6f7b3a77b59769b654e3a1&#34;&gt;Vagrant e &lt;a href=&#34;https://github.com/Parallels/boot2docker-vagrant-box&#34;&gt;parallels/boot2docker&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Leggo su un blog che è possibile avere prestazioni migliori utilizzando un sistema di virtualizzazione alternativo a VirtualBox, come ad esempio Parallels o VMWare Fusion. Per entrambi esistono delle ISO modificate di boot2docker e la macchina dev&amp;rsquo;essere configurata usando Vagrant. La mia scelta cade su &lt;strong&gt;Parallels&lt;/strong&gt;, e finalmente riesco a creare &lt;strong&gt;una macchina performante&lt;/strong&gt; con condivisione NFS.
Purtroppo il mantenimento della ISO sembra non stare al passo con la frequenza di rilascio di Docker (ero fermo alla versione 1.4.1 quando la 1.5 era disponibile da diverse settimane), quindi decido di cambiare nuovamente soluzione.&lt;/p&gt;

&lt;h2 id=&#34;vagrant-e-ubuntu:aeddcc759c6f7b3a77b59769b654e3a1&#34;&gt;Vagrant e Ubuntu&lt;/h2&gt;

&lt;p&gt;Dati i precedenti limiti e relativi fallimenti, tento una strada alternativa e &lt;a href=&#34;https://github.com/ildanno/parallels-docker-vagrantfile&#34;&gt;preparo un Vagrantfile&lt;/a&gt; contenente tutto quello che mi serve: una macchina Ubuntu che gira su Parallels, repository di Docker aggiornato, condivisione NFS e possibilità di eseguire comandi al boot.
Ma ancora una volta ho un problema fastidioso, che si verificava già con la soluzione precedente ma che (sbagliando) attribuivo a boot2docker. Ad ogni avvio della macchina, infatti, si crea &lt;strong&gt;un conflitto&lt;/strong&gt; con OS X per l&amp;rsquo;utilizzo di &lt;strong&gt;alcune risorse di rete&lt;/strong&gt; e devo risolverle manualmente riavviando il demone NAT di Parallels. Inoltre scopro che con vagrant+parallels lo spazio utilizzato dal disco virtuale non è più recuperabile una volta allocato e il mio SSD è ormai alle strette.&lt;/p&gt;

&lt;h2 id=&#34;vm-custom:aeddcc759c6f7b3a77b59769b654e3a1&#34;&gt;VM custom&lt;/h2&gt;

&lt;p&gt;Preso dallo sconforto scelgo di avere il &lt;strong&gt;controllo completo&lt;/strong&gt;: installo &lt;strong&gt;VMWare Fusion&lt;/strong&gt; per avere un sistema di virtualizzazione più performante di VirtualBox, ma senza gli inconvenienti di Parallels, e configuro una macchina con Ubuntu server. Posso montare share NFS e ridimensionare il disco virtuale. Mi sembra una soluzione molto artigianale, ma funziona esattamente come voglio io e credo finalmente di avere trovato la mia pace. Ma non è così.&lt;/p&gt;

&lt;h2 id=&#34;docker-machine:aeddcc759c6f7b3a77b59769b654e3a1&#34;&gt;Docker Machine&lt;/h2&gt;

&lt;p&gt;Da alcune settimane è uscita una novità sul mercato, direttamente da casa Docker, che ho inizialmente ignorato. Si chiama &lt;a href=&#34;https://docs.docker.com/machine/&#34;&gt;Docker Machine&lt;/a&gt; e ad una prima occhiata non sembra fare cose molto diverse da boot2docker, tant&amp;rsquo;è che ne utilizza la stessa ISO. Però il fatto che venga rilasciato direttamente dalla casa madre mi fa ben sperare, vista anche l&amp;rsquo;evoluzione avuta da altri tools come &lt;a href=&#34;https://docs.docker.com/compose/&#34;&gt;Docker Compose&lt;/a&gt;, e dopo qualche tempo decido di dargli una possibilità.&lt;/p&gt;

&lt;p&gt;Mi rendo subito conto che in realtà Docker Machine ha &lt;strong&gt;potenzialità molto maggiori&lt;/strong&gt; di quelle di boot2docker: è in grado di gestire più di una macchina, locale o in cloud, supporta diversi drivers e ha addirittura la possibilità di collegarsi ad un generico server remoto.
Creo quindi una macchina locale, utilizzando il driver di VMWare Fusion:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker-machine create --driver vmwarefusion \
    --vmwarefusion-cpu-count 2 \
    --vmwarefusion-disk-size 40000 \
    --vmwarefusion-memory-size 4096 \
    dev2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In pochi secondi la macchina è pronta all&amp;rsquo;uso. Anche se la cartella &lt;code&gt;/Users&lt;/code&gt; è già montata con il protocollo di condivisione file di VMWare (&lt;code&gt;vmhgfs&lt;/code&gt;), decido comunque di configurare una condivisione NFS personalizzata.&lt;/p&gt;

&lt;p&gt;Per prima cosa configuro OS X in modo da accettare connessioni dalla macchina su cui gira Docker (in questo caso verso la mia cartella &lt;code&gt;~/Sites&lt;/code&gt;):&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ echo &amp;quot;/Users/dcontini/Sites -mapall=dcontini:staff $(docker-machine ip dev2)&amp;quot; | sudo tee -a /etc/exports
$ sudo nfsd restart
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Ora configuro la macchina virtuale, avviando i tools NFS e, se necessario, creando il mount point:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker-machine ssh dev2 -- sudo /usr/local/etc/init.d/nfs-client start
&amp;gt; Starting nfs client utilities.
$ docker-machine ssh dev2 -- sudo mkdir -p /var/www
$ docker-machine ssh dev2 -- sudo mount 172.16.153.1:/Users/dcontini/Sites /var/www
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;A questo punto ho finalmente la mia condivisione NFS e, se voglio, posso configurarne diverse e smontare la cartella &lt;code&gt;/Users&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker-machine ssh dev2 -- mount
.host:/Users on /Users type vmhgfs (rw,relatime)
172.16.153.1:/Users/dcontini/Sites on /var/www type nfs (rw,relatime,...)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Purtroppo ad ogni riavvio della macchina virtuale è necessario &lt;strong&gt;rimontare manualmente la condivisione&lt;/strong&gt;, poiché Docker Machine esegue nuovamente il provisioning. Ma del resto, alla fine di questo viaggio, possiamo dire che si tratta del problema minore ;)&lt;/p&gt;

&lt;p&gt;(Per i più pigri, invece, ho &lt;a href=&#34;https://github.com/ildanno/docker-machine-mount&#34;&gt;pubblicato&lt;/a&gt; &lt;strong&gt;uno script&lt;/strong&gt; che automatizza l&amp;rsquo;operazione)&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Continuous Integration con Docker e Drone</title>
      <link>/engineering.facile.it/blog/ita/continuos-integration-docker-drone/</link>
      <pubDate>Fri, 12 Jun 2015 00:00:00 +0000</pubDate>
      
      <guid>/engineering.facile.it/blog/ita/continuos-integration-docker-drone/</guid>
      <description>

&lt;p&gt;La &lt;strong&gt;continuous integration&lt;/strong&gt; è una pratica che consiste nel &lt;strong&gt;frequente allineamento&lt;/strong&gt;, su di una base comune definita &lt;em&gt;mainline&lt;/em&gt;, delle copie di lavoro degli sviluppatori che collaborano al codice di un progetto.&lt;/p&gt;

&lt;p&gt;Introdotta inizialmente da Grady Booch nel 1991, nella pubblicazione &lt;a href=&#34;http://books.google.com/books?id=w5VQAAAAMAAJ&amp;amp;q=continuous+integration+inauthor:grady+inauthor:booch&amp;amp;dq=continuous+integration+inauthor:grady+inauthor:booch&amp;amp;hl=en&amp;amp;sa=X&amp;amp;ei=0_TxU6TqIMOZyASJ3ICYCQ&amp;amp;ved=0CEQQ6AEwAg&#34;&gt;Object Oriented Design: With Applications&lt;/a&gt;, la pratica è stata estesa e sviluppata all&amp;rsquo;interno dell&amp;rsquo;&lt;strong&gt;extreme programming&lt;/strong&gt;, fino a sostenere la necessità di &lt;strong&gt;allineare&lt;/strong&gt; le copie di lavoro &lt;strong&gt;diverse volte al giorno&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Il vantaggio principale nell&amp;rsquo;adottare la pratica è quello di &lt;strong&gt;evitare l&amp;rsquo;integration hell&lt;/strong&gt; (o merge hell) &lt;strong&gt;minimizzando il rischio&lt;/strong&gt; legato a copie di lavoro divergenti di difficile integrazione.&lt;/p&gt;

&lt;p&gt;Il &lt;a href=&#34;http://engineering.facile.it/tag/software-testing/&#34;&gt;software testing&lt;/a&gt;, pur non essendo indispensabile ai fini della &lt;strong&gt;continuous integration&lt;/strong&gt;, ne è perfettamente complementare, dando allo sviluppatore garanzia di &lt;strong&gt;integrità del funzionamento del software&lt;/strong&gt; prima e dopo l&amp;rsquo;integrazione sulla &lt;em&gt;mainline&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;Risale al 2000 un importante &lt;a href=&#34;http://martinfowler.com/articles/continuousIntegration.html&#34;&gt;articolo&lt;/a&gt; di &lt;a href=&#34;http://martinfowler.com/&#34;&gt;Martin Fowler&lt;/a&gt; che indica i &lt;strong&gt;principi fondamentali&lt;/strong&gt; della CI:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Mantieni un repository del codice sorgente&lt;/li&gt;
&lt;li&gt;Automatizza la build&lt;/li&gt;
&lt;li&gt;Rendi la build auto-testante&lt;/li&gt;
&lt;li&gt;Esegui commit alla baseline tutti i giorni&lt;/li&gt;
&lt;li&gt;Ogni commit fa partire una build automatica&lt;/li&gt;
&lt;li&gt;Ripara immediatamente le build fallite&lt;/li&gt;
&lt;li&gt;Fai in modo che la build sia veloce&lt;/li&gt;
&lt;li&gt;Esegui i test in un clone dell&amp;rsquo;ambiente di produzione&lt;/li&gt;
&lt;li&gt;Fai in modo che sia facile recuperare l&amp;rsquo;ultima build&lt;/li&gt;
&lt;li&gt;Tutti possono vedere lo stato delle build&lt;/li&gt;
&lt;li&gt;Automatizza il deploy&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;soluzioni-per-la-ci-ed-il-testing-automatico:3d304be90cd6edeb527d6149ec7b0239&#34;&gt;Soluzioni per la CI ed il testing automatico&lt;/h2&gt;

&lt;p&gt;Negli ultimi anni si sono diffuse molte &lt;strong&gt;soluzioni software&lt;/strong&gt; che permettono di automatizzare il processo di &lt;strong&gt;build e testing&lt;/strong&gt; a partire da un semplice &lt;em&gt;push&lt;/em&gt; sulla mainline di sviluppo. Ognuno di queste ha le sue peculiari caratteristiche che la rendono diverso dagli altri.&lt;/p&gt;

&lt;p&gt;In Facile.it abbiamo stilato una lista di &lt;strong&gt;requisiti&lt;/strong&gt; per trovare il sistema di CI più adatto al nostro &lt;strong&gt;caso d&amp;rsquo;uso&lt;/strong&gt;:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Possibilità di effettuare build in &lt;strong&gt;ambienti molto diversi&lt;/strong&gt; (per sistema operativo, versioni software..) &lt;strong&gt;identici a quelli di produzione&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Possibilità di effettuare &lt;strong&gt;contemporaneamente&lt;/strong&gt; build multiple, anche appartenenti allo &lt;strong&gt;stesso progetto&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Sistema di CI compatibile con diversi &lt;strong&gt;servizi Git&lt;/strong&gt; (GitHub, GitLab, BitBucket..)&lt;/li&gt;
&lt;li&gt;Integrazione con &lt;strong&gt;chat&lt;/strong&gt; e sistemi di &lt;strong&gt;notifica&lt;/strong&gt; (Slack, IRC..)&lt;/li&gt;
&lt;li&gt;Invio &lt;strong&gt;mail di alert&lt;/strong&gt; per build fallite&lt;/li&gt;
&lt;li&gt;Sistema di CI &lt;strong&gt;estendibile via API&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Dashboard&lt;/strong&gt; che mostri lo stato delle build, per tenere gli &lt;strong&gt;sviluppatori informati&lt;/strong&gt; riguardo lo stato delle proprie build e della mainline&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Utilizzando in maniera intensiva &lt;a href=&#34;https://www.docker.com/&#34;&gt;Docker&lt;/a&gt; per lo sviluppo locale con ambienti &lt;strong&gt;simili alla produzione&lt;/strong&gt;, una caratteristica interessante da avere consiste proprio nella possibilità di effettuare &lt;strong&gt;build all&amp;rsquo;interno di container&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;La nostra scelta è ricaduta su &lt;a href=&#34;https://github.com/drone/drone&#34;&gt;Drone&lt;/a&gt;, una piattaforma di continuous integration piuttosto giovane, ma sufficientemente stabile per un utilizzo in produzione.&lt;/p&gt;

&lt;h2 id=&#34;drone-build-attraverso-container-docker:3d304be90cd6edeb527d6149ec7b0239&#34;&gt;Drone: build attraverso container Docker&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/drone/drone&#34;&gt;Drone&lt;/a&gt;, rilasciato con licenza Apache 2.0, è una piattaforma di CI che automatizza le build &lt;strong&gt;all&amp;rsquo;interno di container Docker&lt;/strong&gt;: la soluzione ideale in un ambiente dove &lt;strong&gt;numerosi gruppi di lavoro&lt;/strong&gt; utilizzano &lt;strong&gt;ambienti molto diversi&lt;/strong&gt; (per sistema operativo, versioni di interpreti di linguaggio, sistemi di database o caching) ma vogliono centralizzare i processi di Continuous Integration.&lt;/p&gt;

&lt;p&gt;Come altre piattaforme di CI, Drone supporta diversi sistemi Git (GitHub, GitLab, BitBucket, Gogs et al.), diversi sistemi di &lt;a href=&#34;https://github.com/drone/drone/blob/v0.2.1/README.md#deployments&#34;&gt;deploy&lt;/a&gt; (Aws S3, SSH, Heroku, Swift et al.) e diversi sistemi di &lt;a href=&#34;https://github.com/drone/drone/blob/v0.2.1/README.md#notifications&#34;&gt;notifica&lt;/a&gt; (Webhook, Hipchat, Email et al.).&lt;/p&gt;

&lt;p&gt;I container di build possono essere avviati in locale o &lt;strong&gt;remoto&lt;/strong&gt;, dal momento che la &lt;a href=&#34;https://github.com/drone/drone#setup&#34;&gt;configurazione&lt;/a&gt; permette di indicare i &lt;strong&gt;socket Docker&lt;/strong&gt; (UNIX, ma anche TCP) da utilizzare.&lt;/p&gt;

&lt;p&gt;Drone supporta un &lt;a href=&#34;https://github.com/drone/drone-plugin-go&#34;&gt;&lt;strong&gt;sistema di plugin&lt;/strong&gt;&lt;/a&gt; estremamente &lt;strong&gt;flessibile&lt;/strong&gt;: un plugin riceve via riga di comando o input dal terminale un JSON contenente le &lt;strong&gt;informazioni sulla build&lt;/strong&gt; corrente e pubblica il risultato in output.&lt;/p&gt;

&lt;p&gt;I plugin vengono distribuiti a loro volta come &lt;strong&gt;container Docker&lt;/strong&gt;, così possono condividere attraverso un volume-mount la &lt;strong&gt;stessa copia del repository&lt;/strong&gt; su cui avviene la build.
L&amp;rsquo;&lt;em&gt;ENTRYPOINT&lt;/em&gt; per il plugin nel Dockerfile &lt;strong&gt;consiste nell&amp;rsquo;eseguibile&lt;/strong&gt; vero e proprio:
in questo modo è possibile scrivere &lt;strong&gt;plugin in qualsiasi linguaggio&lt;/strong&gt; per fare qualsiasi tipo di operazione!&lt;/p&gt;

&lt;p&gt;Per ultimo, ma comunque non di poco conto, il &lt;strong&gt;monitor stato build&lt;/strong&gt; viene rilasciato in un progetto separato: &lt;a href=&#34;https://github.com/drone/drone-wall&#34;&gt;Drone Wall&lt;/a&gt; è semplicemente fantastico!&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;engineering.facile.it/images/continuos-integration-docker-drone/drone-wall.jpg&#34; alt=&#34;Drone wall screenshot&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Quella che segue, è una guida per &lt;strong&gt;l&amp;rsquo;installazione di Drone&lt;/strong&gt; (a sua volta in un container!), molto simile a quella  utilizzata in Facile.it.&lt;/p&gt;

&lt;h2 id=&#34;prerequisiti:3d304be90cd6edeb527d6149ec7b0239&#34;&gt;Prerequisiti&lt;/h2&gt;

&lt;p&gt;Per testare questa guida abbiamo utilizzato Docker 1.6.2 e &lt;a href=&#34;https://docs.docker.com/compose/install/&#34;&gt;docker-compose 1.2.0&lt;/a&gt;.
Per chi non conoscesse Compose, basti sapere che è un &lt;strong&gt;tool per definire convenientemente una configurazione complessa&lt;/strong&gt; (di solito multi-container) in un singolo file &lt;em&gt;yaml&lt;/em&gt;, potendo poi lanciare tutti i container in essa definiti con un singolo conveniente comando anzichè con molti tediosi &lt;code&gt;docker run&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Come prima cosa è necessario clonare il gist, embeddato qui sotto per riferimento, lanciando il seguente comando:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;git clone https://gist.github.com/de5d5861fa4d86f9598c.git
&lt;/code&gt;&lt;/pre&gt;

&lt;script src=&#34;https://gist.github.com/fntlnz/de5d5861fa4d86f9598c.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;Una volta entrati nella cartella del gist, troviamo due file, &lt;em&gt;docker-compose.yml&lt;/em&gt; e &lt;em&gt;nginx.conf&lt;/em&gt;,  descritti in dettaglio di seguito:&lt;/p&gt;

&lt;h2 id=&#34;docker-compose-yml:3d304be90cd6edeb527d6149ec7b0239&#34;&gt;docker-compose.yml&lt;/h2&gt;

&lt;p&gt;Questo file contiene la configurazione dei container che ci permetterà di mettere insieme il nostro ambiente.&lt;/p&gt;

&lt;p&gt;Al suo interno abbiamo &lt;strong&gt;tre nodi&lt;/strong&gt; principali: &lt;em&gt;drone&lt;/em&gt;, &lt;em&gt;nginx&lt;/em&gt; e &lt;em&gt;wall&lt;/em&gt;; analizziamoli singolarmente:&lt;/p&gt;

&lt;h3 id=&#34;drone:3d304be90cd6edeb527d6149ec7b0239&#34;&gt;DRONE&lt;/h3&gt;

&lt;p&gt;Come abbiamo detto in precedenza Drone supporta i vari servizi di hosting repository git, sia open source che PaaS. Per questa guida abbiamo scelto l&amp;rsquo;integrazione più semplice e immediata, quella con &lt;strong&gt;GitHub&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Nel nodo di configurazione di drone ci sono diverse variabili d&amp;rsquo;ambiente: due di queste ci serviranno a configurare l&amp;rsquo;&lt;strong&gt;autenticazione tramite OAuth2&lt;/strong&gt; di GitHub (allo stato attuale, Drone non ha un sistema interno di gestione degli utenti).&lt;/p&gt;

&lt;p&gt;Le variabili d&amp;rsquo;ambiente per GitHub sono &lt;code&gt;DRONE_GITHUB_CLIENT&lt;/code&gt; e &lt;code&gt;DRONE_GITHUB_SECRET&lt;/code&gt;; le chiavi necessarie vengono rilasciate da GitHub a seguito della &lt;a href=&#34;https://github.com/settings/applications/new&#34;&gt;registrazione di una nuova applicazione&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;La variabile d&amp;rsquo;ambiente &lt;code&gt;DRONE_REGISTRATION_OPEN&lt;/code&gt; va settata a &lt;code&gt;false&lt;/code&gt; quando si deciderà di non permettere la &lt;strong&gt;registrazione di nuovi utenti&lt;/strong&gt;, ma è attualmente settata a &lt;code&gt;true&lt;/code&gt; per permettere la registrazione del primo utente, che sarà anche il master dell&amp;rsquo;installazione.&lt;/p&gt;

&lt;p&gt;Un&amp;rsquo;altra variabile d&amp;rsquo;ambiente molto importante è &lt;code&gt;DRONE_WORKER_NODES&lt;/code&gt;: la sua importanza è data dal fatto che contiene il &lt;strong&gt;path del socket di Docker&lt;/strong&gt; che permette la comunicazione con i container. Ogni ripetizione separata da virgola di &lt;code&gt;unix:///var/run/docker.sock&lt;/code&gt; mette a disposizione delle build un nuovo worker per eseguire più build in parallelo.&lt;/p&gt;

&lt;p&gt;Infine, l&amp;rsquo;ultima ma non meno importante variabile d&amp;rsquo;ambiente da impostare è &lt;code&gt;DRONE_SESSION_SECRET&lt;/code&gt;, la chiave che servirà a codificare le sessioni. Una chiave generata &lt;a href=&#34;https://www.random.org/strings/?num=20&amp;amp;len=20&amp;amp;digits=on&amp;amp;upperalpha=on&amp;amp;loweralpha=on&amp;amp;unique=on&amp;amp;format=html&amp;amp;rnd=new&#34;&gt;su Random.org&lt;/a&gt; è perfetta per questo scopo.&lt;/p&gt;

&lt;p&gt;In questo nodo ci sono inoltre &lt;strong&gt;due volumi condivisi&lt;/strong&gt; che sono rispettivamente:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;/data/drone:/var/lib/drone&lt;/code&gt;: il path dove verrà scritto il database SQLite di Drone; eventualmente si può sostituire con un path più adeguato&lt;/li&gt;
&lt;li&gt;&lt;code&gt;/var/run/docker.sock:/var/run/docker.sock&lt;/code&gt;: il path del socket di docker per permettere a Drone di lanciare nuovi container, poiché si trova anche lui all&amp;rsquo;interno di un container&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Un&amp;rsquo;altra riga di questo nodo che è degna di nota è &lt;code&gt;privileged: true&lt;/code&gt;: è infatti &lt;strong&gt;necessario che il container contenente Drone giri in modalità privilegiata&lt;/strong&gt;, per disattivare quei controlli di sicurezza che altrimenti non permetterebbero al container di operare alla creazione, distruzione e modifica di altri container.&lt;/p&gt;

&lt;h3 id=&#34;wall:3d304be90cd6edeb527d6149ec7b0239&#34;&gt;WALL&lt;/h3&gt;

&lt;p&gt;In questo nodo è necessario impostare la variabile d&amp;rsquo;ambiente &lt;code&gt;API_TOKEN&lt;/code&gt;, necessaria ad autorizzare la dashboard di visualizzazione delle build: il token si trova nel proprio profilo utente di Drone una volta avviato. Questa configurazione può essere quindi completata solo dopo aver avviato Drone per la prima volta.&lt;/p&gt;

&lt;h3 id=&#34;nginx:3d304be90cd6edeb527d6149ec7b0239&#34;&gt;NGINX&lt;/h3&gt;

&lt;p&gt;Questo nodo fa il binding della porta 80 dell&amp;rsquo;host verso la porta 80 del container e condivide due volumi, rispettivamente:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;nignx.conf&lt;/code&gt;: condivide la configurazione del file &lt;code&gt;nginx.conf&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;/var/log/nginx:/var/log/nginx&lt;/code&gt;: condivide la cartella contenente i log di NGINX&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code&gt;nginx.conf&lt;/code&gt; va configurato per usare NGINX come proxy di Drone e Drone Wall, utilizzando &lt;a href=&#34;http://nginx.org/en/docs/http/ngx_http_proxy_module.html#proxy_pass&#34;&gt;proxy_pass&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Al suo interno contiene già due &lt;em&gt;server blocks&lt;/em&gt;, i quali a loro volta contengono le direttive &lt;code&gt;server_name&lt;/code&gt;, rispettivamente &lt;code&gt;drone.local&lt;/code&gt; per Drone e &lt;code&gt;wall.drone.local&lt;/code&gt; per il Drone Wall.&lt;/p&gt;

&lt;h2 id=&#34;up-and-running:3d304be90cd6edeb527d6149ec7b0239&#34;&gt;Up And Running&lt;/h2&gt;

&lt;p&gt;Ora che abbiamo completato la configurazione, possiamo semplicemente avviare i nostri container con questo comando, che va eseguito nella cartella contentente il clone del gist di sopra:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker-compose up
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Ora possiamo finalmente utilizzare drone puntando il nostro browser all&amp;rsquo;indirizzo &lt;a href=&#34;http://drone.local&#34;&gt;http://drone.local&lt;/a&gt; (o all&amp;rsquo;indirizzo configurato nel file &lt;code&gt;nginx.conf&lt;/code&gt;)&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>