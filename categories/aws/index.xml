<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>AWS on Facile.it Engineering</title>
    <link>http://engineering.facile.it/categories/aws/</link>
    <description>Recent content in AWS on Facile.it Engineering</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 20 Sep 2016 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://engineering.facile.it/categories/aws/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Event-driven serverless applications</title>
      <link>http://engineering.facile.it/blog/eng/event-driven-serverless-applications/</link>
      <pubDate>Tue, 20 Sep 2016 00:00:00 +0000</pubDate>
      
      <guid>http://engineering.facile.it/blog/eng/event-driven-serverless-applications/</guid>
      <description>

&lt;p&gt;If we think about computing in the Cloud Era, our mind is immediately drawn towards virtual machines and containers. Therefore, for example, when building a production environment with both approaches we think about the need of patching the operating system and/or upgrading the container. At the end of 2014 &lt;strong&gt;Amazon Web Services&lt;/strong&gt; (AWS) announced a new service called &amp;ldquo;&lt;strong&gt;&lt;a href=&#34;https://aws.amazon.com/lambda/&#34;&gt;Lambda&lt;/a&gt;&lt;/strong&gt;&amp;rdquo;, that allows us to focus on business logic and not on infrastructure.&lt;/p&gt;

&lt;h1 id=&#34;what-is-lambda&#34;&gt;What is Lambda?&lt;/h1&gt;

&lt;p&gt;As reported on their website: « &lt;em&gt;AWS Lambda is a serverless compute service that runs your code highly-available in the cloud in response to events and it automatically performs all the administration of the compute resources for you&lt;/em&gt; ». In the previous sentence is condensed all the power of Lambda, that we can summarize with the following key concepts: &lt;strong&gt;&lt;a href=&#34;#serverless-architecture&#34;&gt;serverless architecture&lt;/a&gt;&lt;/strong&gt;, &lt;strong&gt;&lt;a href=&#34;#high-availability&#34;&gt;high-availability&lt;/a&gt;&lt;/strong&gt;, &lt;strong&gt;&lt;a href=&#34;#event-driven&#34;&gt;event-driven&lt;/a&gt;&lt;/strong&gt; and &lt;strong&gt;&lt;a href=&#34;#zero-administration&#34;&gt;zero administration&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://engineering.facile.it/images/event-driven-serverless-applications/aws-lambda-key-concepts.png&#34; alt=&#34;AWS Lambda key concepts&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;serverless-architecture&#34;&gt;Serverless architecture&lt;/h2&gt;

&lt;p&gt;Lambda is completely &amp;ldquo;serverless&amp;rdquo;, a term that can be considered misleading: obviously Lambda uses physical servers to run your code, but we, as the service&amp;rsquo;s users, don’t take care of everything required to do it. We just need to upload our code on AWS console and it handles capacity, scaling, monitoring, logging and security without any server to manage.
Strictly speaking, functions are executed in containers, and kernel-based virtualization is very useful in this context, because it allows to build multiple isolated environments in short time.
A more detailed explanation of serverless architectures can be found &lt;a href=&#34;http://www.martinfowler.com/articles/serverless.html&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;high-availability&#34;&gt;High-availability&lt;/h2&gt;

&lt;p&gt;AWS Lambda maintains compute capacity across multiple availability zones in each region - at the moment there are 8 regions distributed among Americas, EMEA and Asia Pacific - in this way Lambda is able to protect your code against data center failures.&lt;/p&gt;

&lt;h2 id=&#34;event-driven&#34;&gt;Event-driven&lt;/h2&gt;

&lt;p&gt;&amp;ldquo;Event-driven&amp;rdquo; means that a Lambda function is triggered when an event occurs, so the flow of the application is mainly driven by events. In this kind of architecture all Lambda functions are event consumers, because they are invoked by an event and they have the responsibility to process it.
An event comes to life, for example, whenever:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;a new item is created on an Amazon DynamoDB table;&lt;/li&gt;
&lt;li&gt;a file is deleted on an Amazon S3 bucket;&lt;/li&gt;
&lt;li&gt;an Amazon API Gateway is called;&lt;/li&gt;
&lt;li&gt;et cetera&amp;hellip;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;but we can also use AWS SDK to invoke a function directly on a mobile or web app back-end.
This is a good way to write application logic without designing and maintaining a centralized workflow.
More about event-driven programming &lt;a href=&#34;https://en.wikipedia.org/wiki/Event-driven_programming&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;zero-administration&#34;&gt;Zero administration&lt;/h2&gt;

&lt;p&gt;All the work you usually need to do in order to assure that your application works in a scalable, reliable and durable way is taken care by the service itself.  Behind the scenes the system performs all the needed administration for the compute resources, including server and operating system maintenance, code and security patch deployment, code monitoring and logging, and automatically matches the incoming rate of functions invocation for us, to assure capacity provisioning and automatic scaling.&lt;/p&gt;

&lt;h1 id=&#34;lambda-functions&#34;&gt;Lambda functions&lt;/h1&gt;

&lt;p&gt;The code we run on AWS Lambda is called a &amp;ldquo;&lt;strong&gt;lambda function&lt;/strong&gt;&amp;rdquo;. The name &amp;ldquo;lambda&amp;rdquo; derives from the 11th letter of the Greek alphabet. In general a &lt;em&gt;lambda&lt;/em&gt;, also called &lt;em&gt;anonymous function&lt;/em&gt;, is a function that&amp;rsquo;s defined inline (sometimes called &lt;em&gt;closure&lt;/em&gt;) and passed to some other function, method or procedure, to be stored or executed: the &lt;em&gt;anonymity&lt;/em&gt; is given by the fact that we don&amp;rsquo;t give a name to the function, but we just define it at the moment of need.&lt;/p&gt;

&lt;h2 id=&#34;supported-languages&#34;&gt;Supported languages&lt;/h2&gt;

&lt;p&gt;Right now Lambda functions natively support code written in &lt;strong&gt;Java&lt;/strong&gt;, &lt;strong&gt;Node.js&lt;/strong&gt; and &lt;strong&gt;Python&lt;/strong&gt;, but we can run C, Go and PHP using a Node.js wrapper. Hopefully Amazon will add official support for other languages such as PHP, Go, C, Swift and many more. We can also include libraries, even native ones.&lt;/p&gt;

&lt;h2 id=&#34;stateless-code&#34;&gt;Stateless code&lt;/h2&gt;

&lt;p&gt;When we write a function our code must be &lt;strong&gt;stateless&lt;/strong&gt;, thus everything begins and ends in the same request, and any persistent state is stored in a storage service (not necessarily within Amazon world). Keeping functions stateless is the keystone to enable the system to instantly launch new instances when needed, to serve the incoming events.&lt;/p&gt;

&lt;p&gt;In addition to the code, each Lambda function has many configuration informations, such as name, description, runtime, handler, memory, max execution time and execution role. A detailed explanation is available &lt;a href=&#34;https://docs.aws.amazon.com/lambda/latest/dg/lambda-introduction-function.html&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;invocation-types&#34;&gt;Invocation types&lt;/h2&gt;

&lt;p&gt;We can invoke a Lambda function directly, for example using the Invoke API, or indirectly, for example using the Amazon API Gateway. A function invocation needs to specify the &lt;code&gt;InvocationType&lt;/code&gt;. There are three invocation types allowed: &lt;code&gt;RequestResponse&lt;/code&gt;, &lt;code&gt;Event&lt;/code&gt; and &lt;code&gt;DryRun&lt;/code&gt;. Each one of them has different purposes:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;RequestResponse&lt;/code&gt;: in this case we expect a &lt;strong&gt;synchronous&lt;/strong&gt; behavior. The function receives input parameters as an event, and returns a result;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Event&lt;/code&gt;: in this case we expect an &lt;strong&gt;asynchronous&lt;/strong&gt; behavior. The function receives input parameters as an event, returns immediately no value, but continues its execution asynchronously;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;DryRun&lt;/code&gt;: it&amp;rsquo;s used to verify the access to a function without running it.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;http://engineering.facile.it/images/event-driven-serverless-applications/synchronous-vs-asynchronous-behaviour.png&#34; alt=&#34;Synchronous vs asynchronous behaviour&#34; /&gt;&lt;/p&gt;

&lt;h1 id=&#34;lambda-alternatives&#34;&gt;Lambda alternatives&lt;/h1&gt;

&lt;p&gt;Serverless is a new cloud computing trend, and accordingly many cloud providers – in addition to Amazon - started offering their own &lt;em&gt;Function as a Service&lt;/em&gt; (FaaS), for example &lt;strong&gt;Google&lt;/strong&gt; with its &lt;a href=&#34;https://cloud.google.com/functions/&#34;&gt;Cloud Functions&lt;/a&gt;, &lt;strong&gt;IBM&lt;/strong&gt; with its &lt;a href=&#34;https://developer.ibm.com/openwhisk/&#34;&gt;OpenWhisk&lt;/a&gt;, &lt;strong&gt;Auth0&lt;/strong&gt; with its &lt;a href=&#34;https://webtask.io/&#34;&gt;WebTasks&lt;/a&gt; and &lt;strong&gt;Microsoft&lt;/strong&gt; with its &lt;a href=&#34;https://functions.azure.com/&#34;&gt;Azure Functions&lt;/a&gt;.&lt;/p&gt;

&lt;h1 id=&#34;conclusions&#34;&gt;Conclusions&lt;/h1&gt;

&lt;p&gt;Functions are very useful when we want to build lightweight applications based on &lt;em&gt;microservices&lt;/em&gt; with no server. Their approach could be considered a way to achieve fine-grained microservices, in which there is a relation one-to-one between functions and endpoints instead of one service per one resource: for this reason they are often referred to as &lt;em&gt;nanoservices&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;They could help developers in focusing on the code, while only charging for code really running in an infrastructure that&amp;rsquo;s able to autonomously grow upon demand, without lots of efforts in managing it. With functions, we can see our code as a series of small and independent building blocks, that can be easily replaced or connected with other blocks using events. Also, Lamba could help small team in reusing existing skills while adopting different languages, in order to develop software that better matches business&amp;rsquo; requirements.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Da sviluppo a produzione con Docker e AWS Elastic Beanstalk</title>
      <link>http://engineering.facile.it/blog/ita/da-sviluppo-a-produzione-con-docker-e-aws-elastic-beanstalk/</link>
      <pubDate>Mon, 19 Oct 2015 00:00:00 +0000</pubDate>
      
      <guid>http://engineering.facile.it/blog/ita/da-sviluppo-a-produzione-con-docker-e-aws-elastic-beanstalk/</guid>
      <description>

&lt;h2 id=&#34;in-locale-funzionava&#34;&gt;In locale funzionava&lt;/h2&gt;

&lt;p&gt;Questo articolo si rivolge a chi ha già una &lt;a href=&#34;https://docs.docker.com/articles/basics&#34;&gt;conoscenza base di docker&lt;/a&gt; e del suo funzionamento e sta cercando come avanzare al passo successivo, usandolo quotidianamente in sviluppo e in produzione.&lt;/p&gt;

&lt;p&gt;Avere un ambiente di sviluppo/test &lt;strong&gt;il più simile possibile&lt;/strong&gt; a quello di produzione aiuta molto nel garantire un &lt;strong&gt;corretto funzionamento dopo il deploy&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;In uno scenario tipico, lo sviluppatore ha installati sulla propria macchina locale tutti i servizi da cui dipende la sua applicazione, il che comporta quanto segue:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;nessun tipo di isolamento tra progetti che usano gli stessi servizi (versione, configurazione, dati);&lt;/li&gt;
&lt;li&gt;è difficile avere e mantenere in locale la stessa versione e la stessa configurazione dei servizi in produzione;&lt;/li&gt;
&lt;li&gt;condividere l&amp;rsquo;ambiente di sviluppo con colleghi e collaboratori è difficile se non impossibile;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Tutto questo conduce ad una delle peggiori frasi che io abbia mai sentito in tutta la mia esperienza lavorativa:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;It works on my machine &lt;em&gt;(in locale funzionava)&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&#34;http://engineering.facile.it/images/from-development-to-production-with-docker-and-amazon-ecs/wmm.jpg&#34; alt=&#34;It works on my machine meme&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Potreste pensare che avrei potuto ottenere gli stessi risultati usando Vagrant o una classica macchina virtuale, ma questa soluzione non mi avrebbe dato i benefici di avere un layer di astrazione aggiuntivo senza dovermi preoccupare dell&amp;rsquo;overhead. Infatti posso avere molti più container che girano su una singola macchina di quelli che avrei avuto con la semplice virtualizzazione.&lt;/p&gt;

&lt;h2 id=&#34;bookshelf-uno-scaffale-virtuale&#34;&gt;Bookshelf: uno scaffale virtuale&lt;/h2&gt;

&lt;p&gt;Per snellire questo articolo ho preparato un&amp;rsquo;&lt;a href=&#34;https://github.com/pennyphp/bookshelf&#34;&gt;applicazione demo&lt;/a&gt; basata su &lt;a href=&#34;http://github.com/pennyphp/penny&#34;&gt;Penny PHP Framework&lt;/a&gt;: è una semplice applicazione per l&amp;rsquo;archiviazione di libri, che consente all&amp;rsquo;utente di creare e visualizzare una lista di libri.&lt;/p&gt;

&lt;h4 id=&#34;download-e-dipendenze&#34;&gt;Download e dipendenze&lt;/h4&gt;

&lt;p&gt;Per prima cosa, scarichiamo l&amp;rsquo;applicazione dal suo repository:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;git clone https://github.com/pennyphp/bookshelf
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Le dipendenze in PHP sono gestite attraverso &lt;a href=&#34;https://getcomposer.org/&#34;&gt;composer&lt;/a&gt;, e per soddisfarle basta digitare il comando:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;composer install
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Gli assets del frontend sono gestiti attraverso &lt;a href=&#34;http://bower.io&#34;&gt;Bower&lt;/a&gt; + &lt;a href=&#34;http://gruntjs.com/&#34;&gt;Grunt&lt;/a&gt;; i due seguenti comandi scaricheranno e compileranno le dipendenze e produrranno gli assets direttamente nella cartella pubblica:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;npm install
grunt dev
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;avviare-l-ambiente-di-sviluppo&#34;&gt;Avviare l&amp;rsquo;ambiente di sviluppo&lt;/h4&gt;

&lt;p&gt;Come potete vedere l&amp;rsquo;applicazione demo è distribuita con un ambiente di sviluppo docker che potete trovare nella cartella &lt;a href=&#34;https://github.com/pennyphp/bookshelf/tree/master/docker/development&#34;&gt;docker/development&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Osservando il contenuto di &lt;code&gt;docker/development&lt;/code&gt; possiamo trovare altre due cartelle:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;nginx/&lt;/code&gt;: questa directory contiene un Dockerfile che eredita l&amp;rsquo;immagine da &lt;a href=&#34;https://github.com/fntlnz/dockerfiles/tree/master/nginx&#34;&gt;fntlnz/nginx&lt;/a&gt; per crearne una nuova con la configurazione nginx necessaria;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;fpm/&lt;/code&gt;: questa directory contiene un Dockerfile che eredita l&amp;rsquo;immagine da &lt;a href=&#34;https://github.com/fntlnz/dockerfiles/tree/master/php&#34;&gt;fntlnz/php&lt;/a&gt; per crearne una nuova con la configurazione e le estensioni di php-fpm necessarie;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Dal momento che non abbiamo Elastic Beanstalk sulla nostra macchina locale (ne parleremo in seguito) e abbiamo bisogno di un modo per orchestrare i nostri container, lo faremo utilizzando &lt;strong&gt;docker-compose&lt;/strong&gt;. Ho deciso di usare Docker Compose al posto del comando &lt;a href=&#34;http://docs.aws.amazon.com/elasticbeanstalk/latest/dg/eb3-local.html&#34;&gt;&lt;strong&gt;eb local&lt;/strong&gt;&lt;/a&gt; (che consente di far girare l&amp;rsquo;ambiente di elastic beanstalk in locale) perché allo stato dell&amp;rsquo;arte compose è più facile da usare e mantenere in locale.&lt;/p&gt;

&lt;h6 id=&#34;il-file-docker-compose-yml&#34;&gt;Il file &lt;code&gt;docker-compose.yml&lt;/code&gt;&lt;/h6&gt;

&lt;p&gt;Per farlo dobbiamo creare un file &lt;code&gt;docker-compose.yml&lt;/code&gt; nella nostra root di progetto.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;cp docker/docker-compose.yml.development docker-compose.yml
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;A questo punto, nel nostro &lt;code&gt;docker-compose.yml&lt;/code&gt; dovremmo avere quattro container da avviare:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;il container &lt;strong&gt;Nginx&lt;/strong&gt;, che contiene un paragrafo server in ascolto sulla porta 80.&lt;/li&gt;
&lt;li&gt;il container &lt;strong&gt;fpm&lt;/strong&gt;, che condivide un volume con la macchina host in modo da poter modificare il codice senza bisogno di ricostruire il container; inoltre, il container è collegato al container mysql per consentire agli script php di connettervisi;&lt;/li&gt;
&lt;li&gt;il container &lt;strong&gt;mysql&lt;/strong&gt;, che conterrà i nostri dati di sviluppo;&lt;/li&gt;
&lt;li&gt;il container &lt;strong&gt;redis&lt;/strong&gt;, usato come cache, principalmente da Doctrine;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Si noti come, dal momento che &lt;a href=&#34;https://docs.docker.com/userguide/dockerlinks/&#34;&gt;i container sono collegati&lt;/a&gt; è possibile accedere ad un servizio esposto usando il nome assegnato al container collegato; ad esempio, nel nostro caso il container fpm è &lt;a href=&#34;https://github.com/pennyphp/bookshelf/blob/2e55738da9ff9e45fa44add9d97280635e95399d/docker/docker-compose.yml.development#L19-L20&#34;&gt;collegato al container mysql&lt;/a&gt;: è per questo che l&amp;rsquo;host configurato nella &lt;a href=&#34;https://github.com/pennyphp/bookshelf/blob/2e55738da9ff9e45fa44add9d97280635e95399d/config/doctrine.local.php.dist#L13&#34;&gt;configurazione di doctrine locale&lt;/a&gt; è &lt;code&gt;mysql&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Se non l&amp;rsquo;avete ancora fatto, dovrete buildare l&amp;rsquo;immagine &lt;code&gt;fpm&lt;/code&gt; e scaricare le immagini &lt;code&gt;nginx&lt;/code&gt;, &lt;code&gt;mysql&lt;/code&gt; e &lt;code&gt;redis&lt;/code&gt;; per farlo, digitate il comando:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker-compose build
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Ora che avete tutto ciò che vi serve potete avviare i container con:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker-compose up
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;A questo punto i quattro container dovrebbero essere in esecuzione: potete verificare che tutto sia a posto con il comando &lt;code&gt;docker ps&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Per proseguire, abbiamo bisogno di conoscere l&amp;rsquo;indirizzo ip del container nginx. Il port forwarding del container nginx è configurato come &lt;code&gt;80:80&lt;/code&gt;, perciò è disponibile su &lt;strong&gt;linux&lt;/strong&gt; agli indirizzi &lt;code&gt;127.0.0.1:80&lt;/code&gt; e &lt;code&gt;localhost:80&lt;/code&gt;, mentre su &lt;strong&gt;OS X&lt;/strong&gt; all&amp;rsquo;indirizzo associato alla docker-machine; per identificarlo, usare il comando:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker-machine env &amp;lt;yourmachinename&amp;gt; | grep DOCKER_HOST
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;È ora di collegarci all&amp;rsquo;ip del nostro container nginx!&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://engineering.facile.it/images/from-development-to-production-with-docker-and-amazon-ecs/books.png&#34; alt=&#34;Bookshelf screenshot&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Yay! Il nostro ambiente di sviluppo è in esecuzione!&lt;/p&gt;

&lt;h4 id=&#34;configurare-e-attivare-l-ambiente-di-produzione&#34;&gt;Configurare e attivare l&amp;rsquo;ambiente di produzione&lt;/h4&gt;

&lt;p&gt;A questo punto ci serve un modo per rilasciare la nostra applicazione in produzione che possa: eseguire container Docker, scalare senza intoppi e possibilmente aver già installato altri interessanti componenti come, ad esempio, per il monitoring.&lt;/p&gt;

&lt;p&gt;La scelta è caduta su &lt;a href=&#34;https://aws.amazon.com/elasticbeanstalk&#34;&gt;AWS Elastic Beanstalk&lt;/a&gt; ha tutto ciò che abbiamo elencato ed ha inoltre una tariffazione più competitiva con un &lt;a href=&#34;https://aws.amazon.com/free/&#34;&gt;Free Tier&lt;/a&gt; iniziale, sufficiente per far girare questa demo.&lt;/p&gt;

&lt;p&gt;Prima di iniziare abbiamo bisogno di un account &lt;strong&gt;Amazon Web Services&lt;/strong&gt;; se non ne avete ancora uno, potete crearlo &lt;a href=&#34;https://aws.amazon.com/account&#34;&gt;qui&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Per configurare, rilasciare e gestire la nostra infrastruttura avremo bisogno del &lt;a href=&#34;http://docs.aws.amazon.com/elasticbeanstalk/latest/dg/eb-cli3-install.html&#34;&gt;comando eb&lt;/a&gt;; per installarlo, digitare:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;pip install awsebcli
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Per avere accesso alla piattaforma dalla vostra riga di comando usando il comando &lt;strong&gt;eb&lt;/strong&gt; dovrete configurare uno &lt;a href=&#34;http://docs.aws.amazon.com/elasticbeanstalk/latest/dg/AWSHowTo.iam.roles.aeb.html&#34;&gt;&lt;strong&gt;IAM ROLE&lt;/strong&gt;&lt;/a&gt; ed associarlo ad uno &lt;a href=&#34;http://docs.aws.amazon.com/IAM/latest/UserGuide/id_users_create.html&#34;&gt;&lt;strong&gt;IAM User&lt;/strong&gt;&lt;/a&gt;. La creazione assistita di uno IAM User vi &lt;strong&gt;darà due chiavi&lt;/strong&gt;, chiamate &lt;em&gt;AWS Access Key ID&lt;/em&gt; e &lt;em&gt;AWS Secret Access Key&lt;/em&gt;. Ci serviranno durante il prossimo passaggio.&lt;/p&gt;

&lt;p&gt;A questo punto possiamo &lt;strong&gt;initialize&lt;/strong&gt; il nostro progetto Bookshelf. Questo comando ci chiederà le due Access keys, oltre che alcune domande durante l&amp;rsquo;installazione.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;eb init
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Ora che il progetto è inizializzato dobbiamo &lt;strong&gt;creare un nuovo ambiente&lt;/strong&gt;. Questo comando creerà effettivamente un&amp;rsquo;istanza &lt;strong&gt;t2.micro EC2&lt;/strong&gt;, i gruppi di sicurezza, il load balancer, le notifiche cloudwatch ecc..&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;eb create bookshelf-production
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Prima di rilasciare l&amp;rsquo;applicazione in produzione dobbiamo generare un &lt;a href=&#34;https://github.com/settings/tokens/new&#34;&gt;Token Github per composer&lt;/a&gt;.
Questo è necessario per scaricare tutte le dipendenze senza intoppi.
Per aggiungere il token all&amp;rsquo;ambiente:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;eb setenv COMPOSER_TOKEN=&amp;lt;your-token-here&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Ora potete verificare che il sistema sia pronto digitando:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;eb status
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Quando lo stato dell&amp;rsquo;applicazione diventa &lt;strong&gt;Ready&lt;/strong&gt; potete a tutti gli effetti pubblicare l&amp;rsquo;applicazione con:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;eb deploy
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Il deployment creerà i container descritti in &lt;a href=&#34;https://github.com/pennyphp/bookshelf/blob/2e55738da9ff9e45fa44add9d97280635e95399d/Dockerrun.aws.json&#34;&gt;Dockerrun.aws.json&lt;/a&gt; e i files descritti in &lt;a href=&#34;https://github.com/pennyphp/bookshelf/blob/2e55738da9ff9e45fa44add9d97280635e95399d/.ebextensions/dependencies.config&#34;&gt;dependencies.config&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Se vi state chiedendo cosa sia realmente il file &lt;strong&gt;Dockerrun.aws.json&lt;/strong&gt;, basta dire che sta ad Elastic Beanstalk come &lt;code&gt;docker-compose.yml&lt;/code&gt; sta all&amp;rsquo;ambiente locale.&lt;/p&gt;

&lt;p&gt;I file contenuti in &lt;a href=&#34;https://github.com/pennyphp/bookshelf/blob/2e55738da9ff9e45fa44add9d97280635e95399d/.ebextensions/&#34;&gt;.ebextensions&lt;/a&gt; consentono di personalizzare e configurare il software da cui la vostra applicazione dipende. Il file &lt;strong&gt;dependencies.config&lt;/strong&gt; è uno di questi. È proprio lui a risolvere le dipendenze di composer, a compilare gli asset del frontend con grunt e bower e a creare l&amp;rsquo;immagine PHP FPM usata nel &lt;a href=&#34;https://github.com/pennyphp/bookshelf/blob/2e55738da9ff9e45fa44add9d97280635e95399d/docker/production/fpm/Dockerfile&#34;&gt;Dockerfile&lt;/a&gt; di produzione. È importante notare che l&amp;rsquo;immagine viene nuovamente costruita solo se il Dockerfile viene modificato.&lt;/p&gt;

&lt;p&gt;Come avrete notato, [Dockerrun.aws.json](&lt;a href=&#34;https://github.com&#34;&gt;https://github.com&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;La configurazione di default dell&amp;rsquo;applicazione Bookshelf riceve i parametri di connessione a Mysql e Redis &lt;a href=&#34;https://github.com/pennyphp/bookshelf/blob/2e55738da9ff9e45fa44add9d97280635e95399d/config/doctrine.global.php&#34;&gt;dalle variabili d&amp;rsquo;ambiente&lt;/a&gt; che sono:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;MYSQL_HOST
MYSQL_PORT
MYSQL_USERNAME
MYSQL_PASSWORD
MYSQL_DATABASE
REDIS_HOST
REDIS_PORT
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Ognuna di queste variabili d&amp;rsquo;ambiente può essere impostata usando il comando che abbiamo precedentemente usato per &lt;code&gt;COMPOSER_TOKEN&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Potete ottenere i parametri di connessione per Mysql e Redis dopo aver creato &lt;a href=&#34;http://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_CreateInstance.html&#34;&gt;un&amp;rsquo;istanza RDS Mysql DB&lt;/a&gt; e un &lt;a href=&#34;http://docs.aws.amazon.com/opsworks/latest/userguide/other-services-redis-cluster.html&#34;&gt;Cluster ElastiCache Redis&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;A questo punto, con i container nginx e fpm in esecuzione e i database configurati, potete digitare &lt;code&gt;eb open&lt;/code&gt; per aprire l&amp;rsquo;applicazione in produzione e verificare se tutto è ok!&lt;/p&gt;

&lt;p&gt;La vostra infrastruttura, così com&amp;rsquo;è, è anche già pronta per scalare automaticamente; per muovere i primi passi in questa direzione potete dare un&amp;rsquo;occhiata al comando &lt;a href=&#34;http://docs.aws.amazon.com/elasticbeanstalk/latest/dg/eb3-scale.html&#34;&gt;&lt;code&gt;eb scale&lt;/code&gt;&lt;/a&gt; e alla &lt;a href=&#34;http://docs.aws.amazon.com/elasticbeanstalk/latest/dg/using-features.managing.as.html&#34;&gt;documentazione di AWS&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Troubleshooting&lt;/strong&gt;: Se qualcosa dovesse andare storto potete accedere via ssh nella macchina Elastic Beanstalk EC2 con &lt;code&gt;eb ssh&lt;/code&gt; e analizzare lo stato dei container usando strumenti che già conoscete come &lt;code&gt;docker logs&lt;/code&gt;.&lt;/p&gt;

&lt;h4 id=&#34;è-fatta&#34;&gt;È fatta!&lt;/h4&gt;

&lt;p&gt;Ora potete risparmiare un sacco di tempo automatizzando il vostro workflow con docker ed ottenere un ambiente di sviluppo funzionante, auto-contenuto e condivisibile, pur mantenendolo molto simile alla vostra stabile ed efficiente infrastruttura in esecuzione nell&amp;rsquo;ambiente di produzione, sulle cui risorse avete pieno controllo.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://engineering.facile.it/images/from-development-to-production-with-docker-and-amazon-ecs/good-job.jpg&#34; alt=&#34;congratulations&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>From development to production with Docker and AWS Elastic Beanstalk</title>
      <link>http://engineering.facile.it/blog/eng/from-development-to-production-with-docker-and-amazon-ecs/</link>
      <pubDate>Mon, 19 Oct 2015 00:00:00 +0000</pubDate>
      
      <guid>http://engineering.facile.it/blog/eng/from-development-to-production-with-docker-and-amazon-ecs/</guid>
      <description>

&lt;h1 id=&#34;it-works-on-my-machine&#34;&gt;It works on my machine&lt;/h1&gt;

&lt;p&gt;This post is addressed to people who already have &lt;a href=&#34;https://docs.docker.com/articles/basics&#34;&gt;basic knowledge about docker&lt;/a&gt;, about how it works and are looking for a way to move to the next step with the goal of using it in development and production day by day.&lt;/p&gt;

&lt;p&gt;Having a development/testing environment &lt;strong&gt;as close as possible&lt;/strong&gt; to the production one helps a lot in assuring that &lt;strong&gt;things will behave correctly when delivered&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;In a typical scenario, the developer has all the services on which the application depends installed on his local machine, which means the following:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;there&amp;rsquo;s no isolation between projects using the same services (versions, configurations, data);&lt;/li&gt;
&lt;li&gt;it&amp;rsquo;s hard to have and maintain production-like services&amp;rsquo; versions and configurations in development;&lt;/li&gt;
&lt;li&gt;sharing the development environment with co-workers is difficult if not impossible;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;All of that leads to one of the worst sentences I&amp;rsquo;ve ever heard saying in my experience:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;It works on my machine.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&#34;http://engineering.facile.it/images/from-development-to-production-with-docker-and-amazon-ecs/wmm.jpg&#34; alt=&#34;It works on my machine meme&#34; /&gt;&lt;/p&gt;

&lt;p&gt;You might think that I could obtain the same results using Vagrant or plain virtual machines but that solution wouldn&amp;rsquo;t give me the benefit of having an extra layer of abstraction without having to worry about the overhead. In fact I can have more and more containers running on a single machine than I can have with virtualization.&lt;/p&gt;

&lt;h1 id=&#34;bookshelf-application&#34;&gt;Bookshelf application&lt;/h1&gt;

&lt;p&gt;To streamline this article I prepared a &lt;a href=&#34;https://github.com/pennyphp/bookshelf&#34;&gt;demo application&lt;/a&gt; using the &lt;a href=&#34;http://github.com/pennyphp/penny&#34;&gt;Penny PHP Framework&lt;/a&gt;: it&amp;rsquo;s a simple book archiving application, that allows the user to create and view a list of books.&lt;/p&gt;

&lt;h2 id=&#34;download-and-dependencies&#34;&gt;Download and dependencies&lt;/h2&gt;

&lt;p&gt;First, download the demo application from its repository:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;git clone https://github.com/pennyphp/bookshelf
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;PHP Dependencies are managed through &lt;a href=&#34;https://getcomposer.org/&#34;&gt;composer&lt;/a&gt;, and to get them just issue the following:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;composer install
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Frontend assets are managed through &lt;a href=&#34;http://bower.io&#34;&gt;Bower&lt;/a&gt; + &lt;a href=&#34;http://gruntjs.com/&#34;&gt;Grunt&lt;/a&gt;; the following two commands will respectively download build dependencies and then build the assets, by copying them in the public directory:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;npm install
grunt dev
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;up-and-running-development-environment&#34;&gt;Up and running development environment&lt;/h2&gt;

&lt;p&gt;As you can see the demo app comes with a docker development environment that can be found under the &lt;a href=&#34;https://github.com/pennyphp/bookshelf/tree/master/docker/development&#34;&gt;docker/development&lt;/a&gt; folder.&lt;/p&gt;

&lt;p&gt;By inspecting the content of the &lt;code&gt;docker/development&lt;/code&gt; folder we can find two directories:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;nginx/&lt;/code&gt;: this directory contains a Dockerfile that inherits from the &lt;a href=&#34;https://github.com/fntlnz/dockerfiles/tree/master/nginx&#34;&gt;fntlnz/nginx&lt;/a&gt; image to create a new one with the needed nginx configurations;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;fpm/&lt;/code&gt;: this directory contains a Dockerfile that inherits from the &lt;a href=&#34;https://github.com/fntlnz/dockerfiles/tree/master/php&#34;&gt;fntlnz/php&lt;/a&gt; image to create a new one with the needed php-fpm configurations and extensions;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Because we don&amp;rsquo;t have Elastic Beanstalk on our local machine (we&amp;rsquo;ll talk about it later) and we need a way to orchestrate our containers, we&amp;rsquo;ll do it by using &lt;strong&gt;docker-compose&lt;/strong&gt;. I decided to use Docker Compose instead of using the &lt;a href=&#34;http://docs.aws.amazon.com/elasticbeanstalk/latest/dg/eb3-local.html&#34;&gt;&lt;strong&gt;eb local&lt;/strong&gt;&lt;/a&gt; command (which allows to run elastic beanstalk environment in local) because at the state of art compose is easier to use and to manage in local.&lt;/p&gt;

&lt;h4 id=&#34;the-docker-compose-yml&#34;&gt;The &lt;code&gt;docker-compose.yml&lt;/code&gt;&lt;/h4&gt;

&lt;p&gt;In order to do so we have to create a &lt;code&gt;docker-compose.yml&lt;/code&gt; in our project root.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;cp docker/docker-compose.yml.development docker-compose.yml
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;At this point, in our &lt;code&gt;docker-compose.yml&lt;/code&gt; we should have four containers to start:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;the &lt;strong&gt;Nginx&lt;/strong&gt; container, which contains a server block  for the bookshelf application listening on port 80.&lt;/li&gt;
&lt;li&gt;the &lt;strong&gt;fpm&lt;/strong&gt; container, which does have a shared volume with the host machine so you can change the code without the need to rebuild the container image; also, the container is linked with the mysql container to allow mysql access from php scripts;&lt;/li&gt;
&lt;li&gt;the &lt;strong&gt;mysql&lt;/strong&gt; container, which will contain our development data;&lt;/li&gt;
&lt;li&gt;the &lt;strong&gt;redis&lt;/strong&gt; container, used for caching purposes, mainly by Doctrine;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Please note that since &lt;a href=&#34;https://docs.docker.com/userguide/dockerlinks/&#34;&gt;containers are linked&lt;/a&gt; you can access to an exposed service by using the name given to the linked container; for example, in our case the fpm container is &lt;a href=&#34;https://github.com/pennyphp/bookshelf/blob/2e55738da9ff9e45fa44add9d97280635e95399d/docker/docker-compose.yml.development#L19-L20&#34;&gt;linked to the mysql container&lt;/a&gt;: that&amp;rsquo;s why the configured host is &lt;code&gt;mysql&lt;/code&gt; in the &lt;a href=&#34;https://github.com/pennyphp/bookshelf/blob/2e55738da9ff9e45fa44add9d97280635e95399d/config/doctrine.local.php.dist#L13&#34;&gt;doctrine local connection configuration&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;If you haven&amp;rsquo;t done it yet, you need to build the &lt;code&gt;fpm&lt;/code&gt; docker image and download the &lt;code&gt;nginx&lt;/code&gt;, &lt;code&gt;mysql&lt;/code&gt; and &lt;code&gt;redis&lt;/code&gt; images; to do so, issue the following:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker-compose build
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now that you have all what you need you can start the containers with:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker-compose up
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;At this point the four containers should be up and running: you can check if everything&amp;rsquo;s okay by issuing the &lt;code&gt;docker ps&lt;/code&gt; command.&lt;/p&gt;

&lt;p&gt;To proceed, we need to know the ip address of our nginx container. Since the nginx container&amp;rsquo;s port forwarding configuration is &lt;code&gt;80:80&lt;/code&gt;, on &lt;strong&gt;linux&lt;/strong&gt; it should be available at &lt;code&gt;127.0.0.1:80&lt;/code&gt; or &lt;code&gt;localhost:80&lt;/code&gt;, while on &lt;strong&gt;OS X&lt;/strong&gt; it should be available at the ip address associated to the docker-machine host; to retrieve it, issue the following:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker-machine env &amp;lt;yourmachinename&amp;gt; | grep DOCKER_HOST
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It&amp;rsquo;s time to point your browser to the nginx container ip address!&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://engineering.facile.it/images/from-development-to-production-with-docker-and-amazon-ecs/books.png&#34; alt=&#34;Bookshelf screenshot&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Yay! Our development environment is up and running!&lt;/p&gt;

&lt;h2 id=&#34;up-and-running-production-environment&#34;&gt;Up and running production environment&lt;/h2&gt;

&lt;p&gt;At this point we need a solution to deploy our application in production that can: run Docker containers, scale without hassle and possibly have other nice things already setup like, let&amp;rsquo;s say, monitoring.&lt;/p&gt;

&lt;p&gt;The choice fell on &lt;a href=&#34;https://aws.amazon.com/elasticbeanstalk&#34;&gt;AWS Elastic Beanstalk&lt;/a&gt; because it has all those things and in addition it has a more competitive pricing model with an initial &lt;a href=&#34;https://aws.amazon.com/free/&#34;&gt;Free Tier&lt;/a&gt; which it is enough to run this demo.&lt;/p&gt;

&lt;p&gt;Before we start we need an &lt;strong&gt;Amazon Web Services&lt;/strong&gt; account, if you don&amp;rsquo;t have one yet, you can create it &lt;a href=&#34;https://aws.amazon.com/account&#34;&gt;here&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To configure, deploy and manage our infrastructure we are going to need the &lt;a href=&#34;http://docs.aws.amazon.com/elasticbeanstalk/latest/dg/eb-cli3-install.html&#34;&gt;eb command&lt;/a&gt;, to get it:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;pip install awsebcli
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In order to obtain access to the platform from your command line using the &lt;strong&gt;eb&lt;/strong&gt; command you have to setup an &lt;a href=&#34;http://docs.aws.amazon.com/elasticbeanstalk/latest/dg/AWSHowTo.iam.roles.aeb.html&#34;&gt;&lt;strong&gt;IAM ROLE&lt;/strong&gt;&lt;/a&gt; and associate it to an &lt;a href=&#34;http://docs.aws.amazon.com/IAM/latest/UserGuide/id_users_create.html&#34;&gt;&lt;strong&gt;IAM User&lt;/strong&gt;&lt;/a&gt;. The IAM User creation wizard will &lt;strong&gt;give you two keys&lt;/strong&gt;, namely the &lt;em&gt;AWS Access Key ID&lt;/em&gt; and the &lt;em&gt;AWS Secret Access Key&lt;/em&gt;. We are going to need them during the next step.&lt;/p&gt;

&lt;p&gt;At this point we can &lt;strong&gt;initialize&lt;/strong&gt; our bookshelf project. This command will prompt us for the two Access keys plus a few question about our setup.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;eb init
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now that the project is initialized we have to &lt;strong&gt;create a new environment&lt;/strong&gt;. This will actually start a &lt;strong&gt;t2.micro EC2&lt;/strong&gt; instance, create the security groups, the load balancer, cloudwatch alarms etc..&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;eb create bookshelf-production
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Before deploying the application to production we have to generate a &lt;a href=&#34;https://github.com/settings/tokens/new&#34;&gt;Github Token for composer&lt;/a&gt;.
This is needed to allow composer to download dependencies without hassle.
To add the token to your environment:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;eb setenv COMPOSER_TOKEN=&amp;lt;your-token-here&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now you can check if the system is ready issuing a:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;eb status
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;When the status becomes &lt;strong&gt;Ready&lt;/strong&gt; you can actually deploy the application with a:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;eb deploy
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The deployment will create the containers described in the &lt;a href=&#34;https://github.com/pennyphp/bookshelf/blob/2e55738da9ff9e45fa44add9d97280635e95399d/Dockerrun.aws.json&#34;&gt;Dockerrun.aws.json&lt;/a&gt; and create the files described in the &lt;a href=&#34;https://github.com/pennyphp/bookshelf/blob/2e55738da9ff9e45fa44add9d97280635e95399d/.ebextensions/dependencies.config&#34;&gt;dependencies.config&lt;/a&gt; file.&lt;/p&gt;

&lt;p&gt;If you are asking yourslef what the &lt;strong&gt;Dockerrun.aws.json&lt;/strong&gt; actually is, suffice it to say that is to Elastic beanstalk as the &lt;code&gt;docker-compose.yml&lt;/code&gt; is to the local environment.&lt;/p&gt;

&lt;p&gt;The files contained in the &lt;a href=&#34;https://github.com/pennyphp/bookshelf/blob/2e55738da9ff9e45fa44add9d97280635e95399d/.ebextensions/&#34;&gt;.ebextensions&lt;/a&gt; allows you to customize and configure the software that your application depends on. The &lt;strong&gt;dependencies.config&lt;/strong&gt; is one of them. It actually resolves composer dependencies, build frontend assets using grunt and bower and create the PHP FPM image using the production &lt;a href=&#34;https://github.com/pennyphp/bookshelf/blob/2e55738da9ff9e45fa44add9d97280635e95399d/docker/production/fpm/Dockerfile&#34;&gt;Dockerfile&lt;/a&gt;. It&amp;rsquo;s important to note that the image is rebuilt only if changes are made to the Dockerfile.&lt;/p&gt;

&lt;p&gt;As you may have noticed, the &lt;a href=&#34;https://github.com/pennyphp/bookshelf/blob/2e55738da9ff9e45fa44add9d97280635e95399d/Dockerrun.aws.json&#34;&gt;Dockerrun.aws.json&lt;/a&gt; contains definitions just for the Nginx and fpm containers. This is because for &lt;strong&gt;Redis&lt;/strong&gt; and &lt;strong&gt;Mysql&lt;/strong&gt; we are going to use respectively &lt;a href=&#34;https://aws.amazon.com/elasticache/&#34;&gt;&lt;strong&gt;Elasticache&lt;/strong&gt;&lt;/a&gt; and &lt;a href=&#34;https://aws.amazon.com/rds/&#34;&gt;&lt;strong&gt;RDS&lt;/strong&gt;&lt;/a&gt;. RDS and Elasticache are two production ready, scalable and reliable solutions that makes easier to setup a cost-efficient relational database and key value store taking charge of common database administration tasks.&lt;/p&gt;

&lt;p&gt;The Bookshelf application by default is configured to take Mysql and Redis connection parameters &lt;a href=&#34;https://github.com/pennyphp/bookshelf/blob/2e55738da9ff9e45fa44add9d97280635e95399d/config/doctrine.global.php&#34;&gt;from environment variables&lt;/a&gt; which are:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;MYSQL_HOST
MYSQL_PORT
MYSQL_USERNAME
MYSQL_PASSWORD
MYSQL_DATABASE
REDIS_HOST
REDIS_PORT
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Each one of these environment variables can be set using the command we previously used for the &lt;code&gt;COMPOSER_TOKEN&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;You can obtain Mysql and Redis connection parameters after creating an &lt;a href=&#34;http://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_CreateInstance.html&#34;&gt;RDS Mysql DB instance&lt;/a&gt; and an &lt;a href=&#34;http://docs.aws.amazon.com/opsworks/latest/userguide/other-services-redis-cluster.html&#34;&gt;ElastiCache Redis Cluster&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;At this point with the running Nginx and fpm containers and configured databases you can issue an &lt;code&gt;eb open&lt;/code&gt; to open the live production application and see if all&amp;rsquo;s okay!&lt;/p&gt;

&lt;p&gt;As well as ready your infrastructure is also ready to scale and auto scale, to move a first step trough this direction you can take a look at the &lt;a href=&#34;http://docs.aws.amazon.com/elasticbeanstalk/latest/dg/eb3-scale.html&#34;&gt;&lt;code&gt;eb scale&lt;/code&gt;&lt;/a&gt; command and at the &lt;a href=&#34;http://docs.aws.amazon.com/elasticbeanstalk/latest/dg/using-features.managing.as.html&#34;&gt;AWS documentation&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Troubleshooting&lt;/strong&gt;: If something went wrong you can ssh into the elastic beanstalk EC2 machine with a &lt;code&gt;eb ssh&lt;/code&gt; and inspect containers status using tools you already know like &lt;code&gt;docker logs&lt;/code&gt;.&lt;/p&gt;

&lt;h1 id=&#34;you-are-done&#34;&gt;You are done!&lt;/h1&gt;

&lt;p&gt;You can now save a lot of time automating your workflow using docker while having a fully working, self-contained and shareable development environment very close to your running, stable and efficient production infrastructure over which you have full control of the resources.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://engineering.facile.it/images/from-development-to-production-with-docker-and-amazon-ecs/good-job.jpg&#34; alt=&#34;congratulations&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>